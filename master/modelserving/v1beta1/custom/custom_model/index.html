
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="KServe Documentation">
      
      
      
        <link rel="canonical" href="https://kserve.io/website/master/modelserving/v1beta1/custom/custom_model/">
      
      <link rel="icon" href="../../../../images/favicon/favicon-32x32.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-8.0.5">
    
    
      
        <title>How to write a custom predictor - KServe Documentation Website</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.a617204b.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.9204c3b2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deploy-custom-python-serving-runtime-with-inferenceservice" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
 <h1>
   <b>KServe v0.15 is Released</b>, <a href="/website/0.15/blog/articles/2025-05-27-KServe-0.15-release/">Read blog &gt;&gt;</a>
 </h1>

          </div>
        </aside>
      
    </div>
    
      <div data-md-component="outdated" hidden>
        <aside class="md-banner md-banner--warning">
          
        </aside>
      </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="KServe Documentation Website" class="md-header__button md-logo" aria-label="KServe Documentation Website" data-md-component="logo">
      
  <img src="../../../../images/logo/kserve.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            KServe Documentation Website
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              How to write a custom predictor
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/kserve/kserve" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../get_started/" class="md-tabs__link">
        Getting started
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../../admin/serverless/serverless/" class="md-tabs__link">
        Administration Guide
      </a>
    </li>
  

  

  

      
        
  
  
    
  


  
  
  
    

  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../control_plane/" class="md-tabs__link md-tabs__link--active">
        User Guide
      </a>
    </li>
  

  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../reference/api/" class="md-tabs__link">
        API Reference
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../developer/developer/" class="md-tabs__link">
        Developer Guide
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../../blog/articles/2025-05-27-KServe-0.15-release/" class="md-tabs__link">
        Blog
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../community/get_involved/" class="md-tabs__link">
        Community
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="KServe Documentation Website" class="md-nav__button md-logo" aria-label="KServe Documentation Website" data-md-component="logo">
      
  <img src="../../../../images/logo/kserve.png" alt="logo">

    </a>
    KServe Documentation Website
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/kserve/kserve" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Getting started
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Getting started" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Getting started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../get_started/" class="md-nav__link">
        KServe Quickstart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../get_started/first_isvc/" class="md-nav__link">
        First InferenceService
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../get_started/swagger_ui/" class="md-nav__link">
        Interact with InferenceService Swagger UI
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Administration Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Administration Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Administration Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          Install KServe
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Install KServe" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Install KServe
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_1" type="checkbox" id="__nav_3_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1">
          Predictive Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Inference" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          Predictive Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/serverless/serverless/" class="md-nav__link">
        Serverless installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/kubernetes_deployment/" class="md-nav__link">
        Kubernetes deployment installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/modelmesh/" class="md-nav__link">
        ModelMesh installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/serverless/kourier_networking/" class="md-nav__link">
        Kourier Networking Layer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_2" type="checkbox" id="__nav_3_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2">
          Generative Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Generative Inference" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Generative Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/kubernetes_deployment/" class="md-nav__link">
        Kubernetes deployment installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/ai-gateway_integration/" class="md-nav__link">
        AI Gateway Integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/serverless/servicemesh/" class="md-nav__link">
        Istio Service Mesh
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/gatewayapi_migration/" class="md-nav__link">
        Gateway API migration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          User Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1">
          Concepts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Concepts" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_1" type="checkbox" id="__nav_4_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_1">
          Control Plane
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Control Plane" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_1">
          <span class="md-nav__icon md-icon"></span>
          Control Plane
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../control_plane/" class="md-nav__link">
        Model Serving Control Plane
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_2" type="checkbox" id="__nav_4_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_2">
          Data Plane
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Data Plane" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_2">
          <span class="md-nav__icon md-icon"></span>
          Data Plane
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_plane/data_plane/" class="md-nav__link">
        Model Serving Data Plane
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_plane/v1_protocol/" class="md-nav__link">
        V1 Inference Protocol
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_plane/v2_protocol/" class="md-nav__link">
        Open Inference Protocol (V2 Inference Protocol)
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_2_4" type="checkbox" id="__nav_4_1_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_2_4">
          Open Inference Protocol Extensions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Open Inference Protocol Extensions" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_1_2_4">
          <span class="md-nav__icon md-icon"></span>
          Open Inference Protocol Extensions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../data_plane/binary_tensor_data_extension/" class="md-nav__link">
        Binary Tensor Data Extension
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../servingruntimes/" class="md-nav__link">
        Serving Runtimes
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Generative Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Generative Inference" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Generative Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_1" type="checkbox" id="__nav_4_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_1">
          Serving Runtime
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Serving Runtime" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_1">
          <span class="md-nav__icon md-icon"></span>
          Serving Runtime
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../llm/huggingface/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../llm/huggingface/text_generation/" class="md-nav__link">
        Text Generation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../llm/huggingface/text2text_generation/" class="md-nav__link">
        Text2Text Generation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../llm/huggingface/sdk_integration/" class="md-nav__link">
        OpenAI SDK Integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../llm/huggingface/multi-node/" class="md-nav__link">
        Multi Node Inference
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/modelcache/localmodel/" class="md-nav__link">
        Model Cache
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../autoscaling/keda/autoscaling_llm/" class="md-nav__link">
        LLM Autoscaler
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../llm/huggingface/kv_cache_offloading/" class="md-nav__link">
        KV Cache Offloading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../admin/ai-gateway_integration/" class="md-nav__link">
        AI Gateway Integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          Predictive Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Inference" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Predictive Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1" type="checkbox" id="__nav_4_3_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1">
          Model Serving Runtimes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Serving Runtimes" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_1">
          <span class="md-nav__icon md-icon"></span>
          Model Serving Runtimes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_1" type="checkbox" id="__nav_4_3_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_1">
          Supported Model Frameworks/Formats
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Supported Model Frameworks/Formats" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          Supported Model Frameworks/Formats
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../serving_runtime/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/" class="md-nav__link">
        Tensorflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../torchserve/" class="md-nav__link">
        PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sklearn/v2/" class="md-nav__link">
        Scikit-learn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../xgboost/" class="md-nav__link">
        XGBoost
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pmml/" class="md-nav__link">
        PMML
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../spark/" class="md-nav__link">
        Spark MLlib
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../lightgbm/" class="md-nav__link">
        LightGBM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../paddle/" class="md-nav__link">
        Paddle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mlflow/v2/" class="md-nav__link">
        MLFlow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../onnx/" class="md-nav__link">
        ONNX
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_1_12" type="checkbox" id="__nav_4_3_1_1_12" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_1_12">
          Hugging Face
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Hugging Face" data-md-level="5">
        <label class="md-nav__title" for="__nav_4_3_1_1_12">
          <span class="md-nav__icon md-icon"></span>
          Hugging Face
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../huggingface/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../huggingface/token_classification/" class="md-nav__link">
        Token Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../huggingface/text_classification/" class="md-nav__link">
        Text Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../huggingface/fill_mask/" class="md-nav__link">
        Fill Mask
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_2" type="checkbox" id="__nav_4_3_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_2">
          Multi-Framework Serving Runtimes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Multi-Framework Serving Runtimes" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Multi-Framework Serving Runtimes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_2_1" type="checkbox" id="__nav_4_3_1_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_2_1">
          Nvidia Triton
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Nvidia Triton" data-md-level="5">
        <label class="md-nav__title" for="__nav_4_3_1_2_1">
          <span class="md-nav__icon md-icon"></span>
          Nvidia Triton
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../triton/torchscript/" class="md-nav__link">
        TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../triton/bert/" class="md-nav__link">
        Tensorflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../triton/huggingface/" class="md-nav__link">
        Hugging Face
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../amd/" class="md-nav__link">
        AMD
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          How to write a custom predictor
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        How to write a custom predictor
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#create-and-deploy-custom-rest-servingruntime" class="md-nav__link">
    Create and Deploy Custom REST ServingRuntime
  </a>
  
    <nav class="md-nav" aria-label="Create and Deploy Custom REST ServingRuntime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implement-custom-model-using-kserve-api" class="md-nav__link">
    Implement Custom Model using KServe API
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build-custom-serving-image-with-buildpacks" class="md-nav__link">
    Build Custom Serving Image with BuildPacks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-locally-and-test" class="md-nav__link">
    Deploy Locally and Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-the-rest-custom-serving-runtime-on-kserve" class="md-nav__link">
    Deploy the REST Custom Serving Runtime on KServe
  </a>
  
    <nav class="md-nav" aria-label="Deploy the REST Custom Serving Runtime on KServe">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#environment-variables" class="md-nav__link">
    Environment Variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-a-prediction" class="md-nav__link">
    Run a Prediction
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delete-the-inferenceservice" class="md-nav__link">
    Delete the InferenceService
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#create-and-deploy-custom-grpc-servingruntime" class="md-nav__link">
    Create and Deploy Custom gRPC ServingRuntime
  </a>
  
    <nav class="md-nav" aria-label="Create and Deploy Custom gRPC ServingRuntime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup_1" class="md-nav__link">
    Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implement-custom-model-using-kserve-api_1" class="md-nav__link">
    Implement Custom Model using KServe API
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build-custom-serving-image-with-buildpacks_1" class="md-nav__link">
    Build Custom Serving Image with BuildPacks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-locally-and-test_1" class="md-nav__link">
    Deploy Locally and Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-the-grpc-custom-serving-runtime-on-kserve" class="md-nav__link">
    Deploy the gRPC Custom Serving Runtime on KServe
  </a>
  
    <nav class="md-nav" aria-label="Deploy the gRPC Custom Serving Runtime on KServe">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments_1" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-a-grpc-prediction" class="md-nav__link">
    Run a gRPC Prediction
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parallel-model-inference" class="md-nav__link">
    Parallel Model Inference
  </a>
  
    <nav class="md-nav" aria-label="Parallel Model Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup_2" class="md-nav__link">
    Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fractional-gpu-example" class="md-nav__link">
    Fractional GPU example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build-custom-serving-image-with-buildpacks_2" class="md-nav__link">
    Build Custom Serving Image with BuildPacks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-locally-and-test_2" class="md-nav__link">
    Deploy Locally and Test
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuring-logger-for-custom-serving-runtime" class="md-nav__link">
    Configuring Logger for Custom Serving Runtime
  </a>
  
    <nav class="md-nav" aria-label="Configuring Logger for Custom Serving Runtime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-providing-logger-configuration-as-a-dict" class="md-nav__link">
    1. Providing logger configuration as a Dict:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-providing-logger-configuration-as-a-file" class="md-nav__link">
    2. Providing logger configuration as a file:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-disabling-logger-configuration" class="md-nav__link">
    3. Disabling logger Configuration:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_2" type="checkbox" id="__nav_4_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2">
          Multi Model Serving
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Multi Model Serving" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_2">
          <span class="md-nav__icon md-icon"></span>
          Multi Model Serving
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_2_1" type="checkbox" id="__nav_4_3_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2_1">
          Overview
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Overview" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          Overview
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../mms/multi-model-serving/" class="md-nav__link">
        The Scalability Problem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../mms/modelmesh/overview/" class="md-nav__link">
        ModelMesh Overview
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_3" type="checkbox" id="__nav_4_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_3">
          Transformers(pre/post processing)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Transformers(pre/post processing)" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_3">
          <span class="md-nav__icon md-icon"></span>
          Transformers(pre/post processing)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/torchserve_image_transformer/" class="md-nav__link">
        How to write a custom transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/collocation/" class="md-nav__link">
        Collocate transformer and predictor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/feast/" class="md-nav__link">
        Feast
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_4" type="checkbox" id="__nav_4_3_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_4">
          Rollout Strategies
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Rollout Strategies" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_4">
          <span class="md-nav__icon md-icon"></span>
          Rollout Strategies
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../rollout/canary/" class="md-nav__link">
        Canary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../rollout/canary-example/" class="md-nav__link">
        Canary Example
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_5" type="checkbox" id="__nav_4_3_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_5">
          Autoscaling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Autoscaling" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_5">
          <span class="md-nav__icon md-icon"></span>
          Autoscaling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../autoscaling/autoscaling/" class="md-nav__link">
        Knative Autoscaler(KPA)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../autoscaling/raw_deployment_autoscaling/" class="md-nav__link">
        Kubernetes Autoscaler(HPA)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../autoscaling/keda/autoscaling_keda/" class="md-nav__link">
        KEDA Autoscaler
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_6" type="checkbox" id="__nav_4_3_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_6">
          Request Batching
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Request Batching" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_6">
          <span class="md-nav__icon md-icon"></span>
          Request Batching
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../batcher/batcher/" class="md-nav__link">
        Inference Batcher
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_7" type="checkbox" id="__nav_4_3_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_7">
          Payload Logging
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Payload Logging" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_7">
          <span class="md-nav__icon md-icon"></span>
          Payload Logging
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../logger/logger/" class="md-nav__link">
        Inference Logger
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_8" type="checkbox" id="__nav_4_3_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_8">
          Kafka
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Kafka" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_8">
          <span class="md-nav__icon md-icon"></span>
          Kafka
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../kafka/kafka/" class="md-nav__link">
        Inference with Kafka Event Source
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_9" type="checkbox" id="__nav_4_3_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_9">
          Inference Observability
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Inference Observability" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_9">
          <span class="md-nav__icon md-icon"></span>
          Inference Observability
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../observability/prometheus_metrics/" class="md-nav__link">
        Prometheus Metrics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../observability/grafana_dashboards/" class="md-nav__link">
        Grafana Dashboards
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_10" type="checkbox" id="__nav_4_3_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_10">
          Model Explainability
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Explainability" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_10">
          <span class="md-nav__icon md-icon"></span>
          Model Explainability
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../explainer/explainer/" class="md-nav__link">
        Concept
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../explainer/trustyai/" class="md-nav__link">
        TrustyAI Explainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_10_3" type="checkbox" id="__nav_4_3_10_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_10_3">
          Alibi Explainer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Alibi Explainer" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_10_3">
          <span class="md-nav__icon md-icon"></span>
          Alibi Explainer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../explainer/alibi/cifar10/" class="md-nav__link">
        Image Explainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../explainer/alibi/income/" class="md-nav__link">
        Income Explainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../explainer/alibi/moviesentiment/" class="md-nav__link">
        Text Explainer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../explainer/aix/mnist/aix/" class="md-nav__link">
        AIX Explainer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_11" type="checkbox" id="__nav_4_3_11" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_11">
          Model Monitoring
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Monitoring" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_11">
          <span class="md-nav__icon md-icon"></span>
          Model Monitoring
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../detect/alibi_detect/alibi_detect/" class="md-nav__link">
        Alibi Detector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../detect/aif/germancredit/" class="md-nav__link">
        AIF Bias Detector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../detect/art/mnist/" class="md-nav__link">
        ART Adversarial Detector
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_4" type="checkbox" id="__nav_4_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_4">
          Inference Graph
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Inference Graph" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Inference Graph
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../inference_graph/" class="md-nav__link">
        Concept
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../inference_graph/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../inference_graph/image_pipeline/" class="md-nav__link">
        Image classification inference graph
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_5" type="checkbox" id="__nav_4_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_5">
          Model Storage
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Storage" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_5">
          <span class="md-nav__icon md-icon"></span>
          Model Storage
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/storagecontainers/" class="md-nav__link">
        Storage Containers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../certificate/kserve/" class="md-nav__link">
        Configure CA Certificate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/azure/azure/" class="md-nav__link">
        Azure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/pvc/pvc/" class="md-nav__link">
        PVC
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/s3/s3/" class="md-nav__link">
        S3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/oci/" class="md-nav__link">
        OCI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/uri/uri/" class="md-nav__link">
        URI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/gcs/gcs/" class="md-nav__link">
        GCS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../storage/huggingface/hf/" class="md-nav__link">
        Hugging Face
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_6" type="checkbox" id="__nav_4_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_6">
          Node Scheduling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Node Scheduling" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_6">
          <span class="md-nav__icon md-icon"></span>
          Node Scheduling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../nodescheduling/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../nodescheduling/inferenceservicenodescheduling/" class="md-nav__link">
        InferenceService Node Scheduling
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../reference/api/" class="md-nav__link">
        Control Plane API
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../reference/swagger-ui/" class="md-nav__link">
        Open Inference Protocol API Spec
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../sdk_docs/sdk_doc/" class="md-nav__link">
        Python Client SDK
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../python_runtime_api/docs/" class="md-nav__link">
        Python Runtime Server SDK
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../inference_client/doc/" class="md-nav__link">
        Inference Python Client
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Developer Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Developer Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Developer Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../developer/developer/" class="md-nav__link">
        How to contribute
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../developer/debug/" class="md-nav__link">
        Debugging guide
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Blog
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Blog" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Blog
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1" type="checkbox" id="__nav_7_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_1">
          Releases
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Releases" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_1">
          <span class="md-nav__icon md-icon"></span>
          Releases
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2025-05-27-KServe-0.15-release/" class="md-nav__link">
        KServe 0.15 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2024-12-13-KServe-0.14-release/" class="md-nav__link">
        KServe 0.14 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2024-05-15-KServe-0.13-release/" class="md-nav__link">
        KServe 0.13 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2023-10-08-KServe-0.11-release/" class="md-nav__link">
        KServe 0.11 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2023-02-05-KServe-0.10-release/" class="md-nav__link">
        KServe 0.10 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2022-07-21-KServe-0.9-release/" class="md-nav__link">
        KServe 0.9 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2022-02-18-KServe-0.8-release/" class="md-nav__link">
        KServe 0.8 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../blog/articles/2021-10-11-KServe-0.7-release/" class="md-nav__link">
        KServe 0.7 Release
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" type="checkbox" id="__nav_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8">
          Community
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Community" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Community
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../community/get_involved/" class="md-nav__link">
        How to Get Involved
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../community/adopters/" class="md-nav__link">
        Adopters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../community/presentations/" class="md-nav__link">
        Demos and Presentations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#create-and-deploy-custom-rest-servingruntime" class="md-nav__link">
    Create and Deploy Custom REST ServingRuntime
  </a>
  
    <nav class="md-nav" aria-label="Create and Deploy Custom REST ServingRuntime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implement-custom-model-using-kserve-api" class="md-nav__link">
    Implement Custom Model using KServe API
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build-custom-serving-image-with-buildpacks" class="md-nav__link">
    Build Custom Serving Image with BuildPacks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-locally-and-test" class="md-nav__link">
    Deploy Locally and Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-the-rest-custom-serving-runtime-on-kserve" class="md-nav__link">
    Deploy the REST Custom Serving Runtime on KServe
  </a>
  
    <nav class="md-nav" aria-label="Deploy the REST Custom Serving Runtime on KServe">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#environment-variables" class="md-nav__link">
    Environment Variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-a-prediction" class="md-nav__link">
    Run a Prediction
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#delete-the-inferenceservice" class="md-nav__link">
    Delete the InferenceService
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#create-and-deploy-custom-grpc-servingruntime" class="md-nav__link">
    Create and Deploy Custom gRPC ServingRuntime
  </a>
  
    <nav class="md-nav" aria-label="Create and Deploy Custom gRPC ServingRuntime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup_1" class="md-nav__link">
    Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implement-custom-model-using-kserve-api_1" class="md-nav__link">
    Implement Custom Model using KServe API
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build-custom-serving-image-with-buildpacks_1" class="md-nav__link">
    Build Custom Serving Image with BuildPacks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-locally-and-test_1" class="md-nav__link">
    Deploy Locally and Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-the-grpc-custom-serving-runtime-on-kserve" class="md-nav__link">
    Deploy the gRPC Custom Serving Runtime on KServe
  </a>
  
    <nav class="md-nav" aria-label="Deploy the gRPC Custom Serving Runtime on KServe">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arguments_1" class="md-nav__link">
    Arguments
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-a-grpc-prediction" class="md-nav__link">
    Run a gRPC Prediction
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parallel-model-inference" class="md-nav__link">
    Parallel Model Inference
  </a>
  
    <nav class="md-nav" aria-label="Parallel Model Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup_2" class="md-nav__link">
    Setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fractional-gpu-example" class="md-nav__link">
    Fractional GPU example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#build-custom-serving-image-with-buildpacks_2" class="md-nav__link">
    Build Custom Serving Image with BuildPacks
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploy-locally-and-test_2" class="md-nav__link">
    Deploy Locally and Test
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuring-logger-for-custom-serving-runtime" class="md-nav__link">
    Configuring Logger for Custom Serving Runtime
  </a>
  
    <nav class="md-nav" aria-label="Configuring Logger for Custom Serving Runtime">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-providing-logger-configuration-as-a-dict" class="md-nav__link">
    1. Providing logger configuration as a Dict:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-providing-logger-configuration-as-a-file" class="md-nav__link">
    2. Providing logger configuration as a file:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-disabling-logger-configuration" class="md-nav__link">
    3. Disabling logger Configuration:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/kserve/website/edit/main/docs/modelserving/v1beta1/custom/custom_model/README.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>


<h1 id="deploy-custom-python-serving-runtime-with-inferenceservice">Deploy Custom Python Serving Runtime with InferenceService<a class="headerlink" href="#deploy-custom-python-serving-runtime-with-inferenceservice" title="Permanent link">&para;</a></h1>
<p>When the out-of-the-box <code>Serving Runtime</code> does not fit your need, you can choose to build your own model server using <code>KServe ModelServer API</code>
to deploy as <code>Custom Serving Runtime</code> on KServe.</p>
<h2 id="create-and-deploy-custom-rest-servingruntime">Create and Deploy Custom REST ServingRuntime<a class="headerlink" href="#create-and-deploy-custom-rest-servingruntime" title="Permanent link">&para;</a></h2>
<h3 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">&para;</a></h3>
<ol>
<li>Install <a href="https://buildpacks.io/docs/tools/pack/">pack CLI</a> to build your custom model server image.</li>
<li><a href="./rest">The code samples</a> can be found in the KServe website repository.</li>
</ol>
<h3 id="implement-custom-model-using-kserve-api">Implement Custom Model using KServe API<a class="headerlink" href="#implement-custom-model-using-kserve-api" title="Permanent link">&para;</a></h3>
<p><code>KServe.Model</code> base class mainly defines three handlers <code>preprocess</code>, <code>predict</code> and <code>postprocess</code>, these handlers are executed
in sequence, the output of the <code>preprocess</code> is passed to <code>predict</code> as the input, the <code>predictor</code> handler executes the
inference for your model, the <code>postprocess</code> handler then turns the raw prediction result into user-friendly inference response. There
is an additional <code>load</code> handler which is used for writing custom code to load your model into the memory from local file system or
remote model storage, a general good practice is to call the <code>load</code> handler in the model server class <code>__init__</code> function, so your model
is loaded on startup and ready to serve prediction requests.</p>
<div class="highlight"><span class="filename">model.py</span><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">fastapi.middleware.cors</span><span class="w"> </span><span class="kn">import</span> <span class="n">CORSMiddleware</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">kserve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelServer</span><span class="p">,</span> <span class="n">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve.model_server</span><span class="w"> </span><span class="kn">import</span> <span class="n">app</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">generate_uuid</span>


<span class="k">class</span><span class="w"> </span><span class="nc">AlexNetModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">return_response_headers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># The ready flag is used by model ready endpoint for readiness probes,</span>
        <span class="c1"># set to True when model is loaded successfully without exceptions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">payload</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">headers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">response_headers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="c1"># Input follows the Tensorflow V1 HTTP API for binary values</span>
        <span class="c1"># https://www.tensorflow.org/tfx/serving/api_rest#encoding_binary_values</span>
        <span class="n">img_data</span> <span class="o">=</span> <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="s2">&quot;b64&quot;</span><span class="p">]</span>
        <span class="n">raw_img_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">img_data</span><span class="p">)</span>
        <span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">raw_img_data</span><span class="p">))</span>
        <span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
        <span class="p">])</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">values</span><span class="p">,</span> <span class="n">top_5</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">response_id</span> <span class="o">=</span> <span class="n">generate_uuid</span><span class="p">()</span>

        <span class="c1"># Custom response headers can be added to the inference response</span>
        <span class="k">if</span> <span class="n">response_headers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">response_headers</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;prediction-time-latency&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="mi">9</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">result</span><span class="p">}</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">kserve</span><span class="o">.</span><span class="n">model_server</span><span class="o">.</span><span class="n">parser</span><span class="p">])</span>
<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Configure kserve and uvicorn logger</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_config_file</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AlexNetModel</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="c1"># Custom middlewares can be added to the model</span>
    <span class="n">app</span><span class="o">.</span><span class="n">add_middleware</span><span class="p">(</span>
        <span class="n">CORSMiddleware</span><span class="p">,</span>
        <span class="n">allow_origins</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;*&quot;</span><span class="p">],</span>
        <span class="n">allow_credentials</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">allow_methods</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;*&quot;</span><span class="p">],</span>
        <span class="n">allow_headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;*&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">ModelServer</span><span class="p">()</span><span class="o">.</span><span class="n">start</span><span class="p">([</span><span class="n">model</span><span class="p">])</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code>return_response_headers=True</code> can be added to return response headers for v1 and v2 endpoints</p>
</div>
<h3 id="build-custom-serving-image-with-buildpacks">Build Custom Serving Image with BuildPacks<a class="headerlink" href="#build-custom-serving-image-with-buildpacks" title="Permanent link">&para;</a></h3>
<p><a href="https://buildpacks.io/">Buildpacks</a> allows you to transform your inference code into images that can be deployed on KServe without
needing to define the <code>Dockerfile</code>. Buildpacks automatically determines the python application and then install the dependencies from the
<code>requirements.txt</code> file, it looks at the <code>Procfile</code> to determine how to start the model server. Here we are showing how to build the serving
image manually with <code>pack</code>, you can also choose to use <a href="https://github.com/pivotal/kpack">kpack</a>
to run the image build on the cloud and continuously build/deploy new versions from your source git repository.</p>
<p>You can use pack cli to build and push the custom model server image
<div class="highlight"><pre><span></span><code>pack<span class="w"> </span>build<span class="w"> </span>--builder<span class="o">=</span>heroku/builder:24<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model:v1
docker<span class="w"> </span>push<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model:v1
</code></pre></div></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If your buildpack command fails, make sure you have a <a href="rest/.python-version"><code>.python-version</code></a> file with the correct python version specified and a <a href="rest/Procfile"><code>Procfile</code></a> with correct entrypoint and arguments.</p>
</div>
<h3 id="deploy-locally-and-test">Deploy Locally and Test<a class="headerlink" href="#deploy-locally-and-test" title="Permanent link">&para;</a></h3>
<p>Launch the docker image built from last step.
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>run<span class="w"> </span>-ePORT<span class="o">=</span><span class="m">8080</span><span class="w"> </span>-p8080:8080<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model:v1
</code></pre></div></p>
<p>Send a test inference request locally with <a href="input.json">input.json</a>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>localhost:8080/v1/models/custom-model:predict<span class="w"> </span>-d<span class="w"> </span>@./input.json
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code><span class="p">{</span><span class="nt">&quot;predictions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="mf">14.861763000488281</span><span class="p">,</span><span class="w"> </span><span class="mf">13.94291877746582</span><span class="p">,</span><span class="w"> </span><span class="mf">13.924378395080566</span><span class="p">,</span><span class="w"> </span><span class="mf">12.182709693908691</span><span class="p">,</span><span class="w"> </span><span class="mf">12.00634765625</span><span class="p">]]}</span>
</code></pre></div>
</div>
<h3 id="deploy-the-rest-custom-serving-runtime-on-kserve">Deploy the REST Custom Serving Runtime on KServe<a class="headerlink" href="#deploy-the-rest-custom-serving-runtime-on-kserve" title="Permanent link">&para;</a></h3>
<p><div class="highlight"><span class="filename">custom.yaml</span><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">custom-model</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-container</span>
<span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${DOCKER_USER}/custom-model:v1</span>
</code></pre></div>
In the <code>custom.yaml</code> file edit the container image and replace ${DOCKER_USER} with your Docker Hub username.</p>
<h4 id="arguments">Arguments<a class="headerlink" href="#arguments" title="Permanent link">&para;</a></h4>
<p>You can supply additional command arguments on the container spec to configure the model server.</p>
<ul>
<li><code>--workers</code>: Spawn the specified number of <code>uvicorn</code> workers(multi-processing) of the model server, the default value is 1, this option is often used
  to help increase the resource utilization of the container.</li>
<li><code>--http_port</code>: The http port model server is listening on, the default REST port is 8080.</li>
<li><code>--grpc_port</code>: The GRPC Port listened to by the model server. Default is 8081.</li>
<li><code>--max_threads</code>: The max number of gRPC processing threads. Default is 4.</li>
<li><code>--enable_grpc</code>: Enable gRPC for the model server. Default is true.</li>
<li><code>--grpc_max_send_message_length</code>: The max message length for gRPC send message. Default is 8388608 bytes (8 MB).</li>
<li><code>--grpc_max_receive_message_length</code>: The max message length for gRPC receive message. Default is 8388608 bytes (8 MB).</li>
<li><code>--model_name</code>: The model name deployed in the model server, the default name the same as the service name.</li>
<li><code>--max_asyncio_workers</code>: Max number of workers to spawn for python async io loop, by default it is <code>min(32,cpu.limit + 4)</code>.</li>
<li><code>--enable_latency_logging</code>: Whether to log latency metrics per request, the default is True.</li>
<li><code>--configure_logging</code>: Whether to configure KServe and Uvicorn logging, the default is True.</li>
<li><code>--log_config_file</code>: The path of the Python config file configuration to use (can be a json, a yaml file or any other supported file format by 
python logging module). This file allows to override the default Uvicorn configuration shipped with KServe. The default is None.</li>
<li><code>--access_log_format</code>: A string representing the access log format configuration to use. The functionality is provided by the <code>asgi-logger</code> library and it allows to override only the <code>uvicorn.access</code>'s format configuration with a richer set of fields (output hardcoded to <code>stdout</code>). This limitation is currently due to the ASGI specs that don't describe how access logging should be implemented in detail (please refer to this Uvicorn <a href="https://github.com/encode/uvicorn/issues/527">github issue</a> for more info). By default is None.</li>
<li><code>enable_latency_logging</code>: whether to log latency metrics per request, the default is True.</li>
<li><code>--enable_docs_url</code>: Enable docs url '/docs' to display Swagger UI.</li>
</ul>
<h4 id="environment-variables">Environment Variables<a class="headerlink" href="#environment-variables" title="Permanent link">&para;</a></h4>
<p>You can supply additional environment variables on the container spec.</p>
<ul>
<li><code>STORAGE_URI</code>: load a model from a storage system supported by KServe e.g. <code>pvc://</code> <code>s3://</code>. This acts the same as <code>storageUri</code> when using a built-in predictor.
  The data will be available at <code>/mnt/models</code> in the container. For example, the following <code>STORAGE_URI: "pvc://my_model/model.onnx"</code> will be accessible at <code>/mnt/models/model.onnx</code></li>
<li><code>PROTOCOL</code>: specify the protocol version supported by the model e.g <code>V1</code>. This acts the same as <code>protocolVersion</code> when using a built-in predictor.</li>
<li><code>KSERVE_LOGLEVEL</code>: sets the <code>kserve</code> and <code>kserve_trace</code>'s logger verbosity. Default is <code>INFO</code>.</li>
</ul>
<p>Apply the YAML to deploy the InferenceService on KServe</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">kubectl</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight"><pre><span></span><code>kubectl apply -f custom.yaml
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>$<span class="w"> </span>inferenceservice.serving.kserve.io/custom-model<span class="w"> </span>created
</code></pre></div>
</div>
<h3 id="run-a-prediction">Run a Prediction<a class="headerlink" href="#run-a-prediction" title="Permanent link">&para;</a></h3>
<p>The first step is to <a href="../../../../get_started/first_isvc/#4-determine-the-ingress-ip-and-ports">determine the ingress IP and ports</a> and set <code>INGRESS_HOST</code> and <code>INGRESS_PORT</code></p>
<div class="highlight"><pre><span></span><code><span class="nv">MODEL_NAME</span><span class="o">=</span>custom-model
<span class="nv">INPUT_PATH</span><span class="o">=</span>@./input.json
<span class="nv">SERVICE_HOSTNAME</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>inferenceservice<span class="w"> </span><span class="si">${</span><span class="nv">MODEL_NAME</span><span class="si">}</span><span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.status.url}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="w"> </span><span class="s2">&quot;/&quot;</span><span class="w"> </span>-f<span class="w"> </span><span class="m">3</span><span class="k">)</span>

curl<span class="w"> </span>-v<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Host: </span><span class="si">${</span><span class="nv">SERVICE_HOSTNAME</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>http://<span class="si">${</span><span class="nv">INGRESS_HOST</span><span class="si">}</span>:<span class="si">${</span><span class="nv">INGRESS_PORT</span><span class="si">}</span>/v1/models/<span class="si">${</span><span class="nv">MODEL_NAME</span><span class="si">}</span>:predict<span class="w"> </span>-d<span class="w"> </span><span class="nv">$INPUT_PATH</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>*<span class="w">   </span>Trying<span class="w"> </span><span class="m">169</span>.47.250.204...
*<span class="w"> </span>TCP_NODELAY<span class="w"> </span><span class="nb">set</span>
*<span class="w"> </span>Connected<span class="w"> </span>to<span class="w"> </span><span class="m">169</span>.47.250.204<span class="w"> </span><span class="o">(</span><span class="m">169</span>.47.250.204<span class="o">)</span><span class="w"> </span>port<span class="w"> </span><span class="m">80</span><span class="w"> </span><span class="o">(</span><span class="c1">#0)</span>
&gt;<span class="w"> </span>POST<span class="w"> </span>/v1/models/custom-model:predict<span class="w"> </span>HTTP/1.1
&gt;<span class="w"> </span>Host:<span class="w"> </span>custom-model.default.example.com
&gt;<span class="w"> </span>User-Agent:<span class="w"> </span>curl/7.64.1
&gt;<span class="w"> </span>Accept:<span class="w"> </span>*/*
&gt;<span class="w"> </span>Content-Length:<span class="w"> </span><span class="m">105339</span>
&gt;<span class="w"> </span>Content-Type:<span class="w"> </span>application/x-www-form-urlencoded
&gt;<span class="w"> </span>Expect:<span class="w"> </span><span class="m">100</span>-continue
&gt;
&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">100</span><span class="w"> </span>Continue
*<span class="w"> </span>We<span class="w"> </span>are<span class="w"> </span>completely<span class="w"> </span>uploaded<span class="w"> </span>and<span class="w"> </span>fine
&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">200</span><span class="w"> </span>OK
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">232</span>
&lt;<span class="w"> </span>content-type:<span class="w"> </span>text/html<span class="p">;</span><span class="w"> </span><span class="nv">charset</span><span class="o">=</span>UTF-8
&lt;<span class="w"> </span>date:<span class="w"> </span>Wed,<span class="w"> </span><span class="m">26</span><span class="w"> </span>Feb<span class="w"> </span><span class="m">2020</span><span class="w"> </span><span class="m">15</span>:19:15<span class="w"> </span>GMT
&lt;<span class="w"> </span>server:<span class="w"> </span>istio-envoy
&lt;<span class="w"> </span>x-envoy-upstream-service-time:<span class="w"> </span><span class="m">213</span>
&lt;
*<span class="w"> </span>Connection<span class="w"> </span><span class="c1">#0 to host 169.47.250.204 left intact</span>
<span class="o">{</span><span class="s2">&quot;predictions&quot;</span>:<span class="w"> </span><span class="o">[[</span><span class="m">14</span>.861762046813965,<span class="w"> </span><span class="m">13</span>.942917823791504,<span class="w"> </span><span class="m">13</span>.9243803024292,<span class="w"> </span><span class="m">12</span>.182711601257324,<span class="w"> </span><span class="m">12</span>.00634765625<span class="o">]]}</span>
</code></pre></div>
</div>
<h3 id="delete-the-inferenceservice">Delete the InferenceService<a class="headerlink" href="#delete-the-inferenceservice" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>delete<span class="w"> </span>-f<span class="w"> </span>custom.yaml
</code></pre></div>
<h2 id="create-and-deploy-custom-grpc-servingruntime">Create and Deploy Custom gRPC ServingRuntime<a class="headerlink" href="#create-and-deploy-custom-grpc-servingruntime" title="Permanent link">&para;</a></h2>
<p>KServe gRPC ServingRuntimes enables high performance inference data plane which implements the <code>Open(v2) Inference Protocol</code>:</p>
<ul>
<li>gRPC is built on top of HTTP/2 for addressing the
  shortcomings of <a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">head-of-line-blocking</a> and <a href="https://en.wikipedia.org/wiki/HTTP_pipelining">pipelining</a>,</li>
<li>gRPC transports binary data format with <a href="https://github.com/protocolbuffers/protobuf">Protobuf</a> which is efficient to send over the wire.</li>
</ul>
<p>Compared to REST it has limited support for browser and the message is not human-readable which requires additional debugging tools.</p>
<h3 id="setup_1">Setup<a class="headerlink" href="#setup_1" title="Permanent link">&para;</a></h3>
<ol>
<li>Install <a href="https://buildpacks.io/docs/tools/pack/">pack CLI</a> to build your custom model server image.</li>
<li><a href="./grpc">The code samples</a> can be found in the KServe website repository.</li>
</ol>
<h3 id="implement-custom-model-using-kserve-api_1">Implement Custom Model using KServe API<a class="headerlink" href="#implement-custom-model-using-kserve-api_1" title="Permanent link">&para;</a></h3>
<p>For <code>Open(v2) Inference Protocol</code>, KServe provides <code>InferRequest</code> and <code>InferResponse</code> API object for <code>predict</code>, <code>preprocess</code>, <code>postprocess</code>
handlers to abstract away the implementation details of REST/gRPC decoding and encoding over the wire.</p>
<div class="highlight"><span class="filename">model_grpc.py</span><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferRequest</span><span class="p">,</span> <span class="n">InferResponse</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelServer</span><span class="p">,</span> <span class="n">logging</span><span class="p">,</span> <span class="n">model_server</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve.utils.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_predict_response</span>

<span class="c1"># This custom predictor example implements the custom model following KServe</span>
<span class="c1"># v2 inference gPPC protocol, the input can be raw image bytes or image tensor</span>
<span class="c1"># which is pre-processed by transformer and then passed to predictor, the</span>
<span class="c1"># output is the prediction response.</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AlexNetModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># The ready flag is used by model ready endpoint for readiness probes,</span>
        <span class="c1"># set to True when model is loaded successfully without exceptions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span> <span class="n">InferRequest</span><span class="p">,</span>
        <span class="n">headers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">response_headers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InferResponse</span><span class="p">:</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">payload</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">req</span><span class="o">.</span><span class="n">datatype</span> <span class="o">==</span> <span class="s2">&quot;BYTES&quot;</span><span class="p">:</span>
            <span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">req</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
                        <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                    <span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">req</span><span class="o">.</span><span class="n">datatype</span> <span class="o">==</span> <span class="s2">&quot;FP32&quot;</span><span class="p">:</span>
            <span class="n">np_array</span> <span class="o">=</span> <span class="n">payload</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">()</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">values</span><span class="p">,</span> <span class="n">top_5</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">get_predict_response</span><span class="p">(</span><span class="n">payload</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">model_server</span><span class="o">.</span><span class="n">parser</span><span class="p">])</span>
<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Configure kserve and uvicorn logger</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_config_file</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AlexNetModel</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="n">ModelServer</span><span class="p">()</span><span class="o">.</span><span class="n">start</span><span class="p">([</span><span class="n">model</span><span class="p">])</span>
</code></pre></div>
<h3 id="build-custom-serving-image-with-buildpacks_1">Build Custom Serving Image with BuildPacks<a class="headerlink" href="#build-custom-serving-image-with-buildpacks_1" title="Permanent link">&para;</a></h3>
<p>Similar to building the REST custom image, you can also use pack cli to build and push the custom gRPC model server image
<div class="highlight"><pre><span></span><code>pack<span class="w"> </span>build<span class="w"> </span>--builder<span class="o">=</span>heroku/builder:24<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model-grpc:v1
docker<span class="w"> </span>push<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model-grpc:v1
</code></pre></div></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If your buildpack command fails, make sure you have a <a href="grpc/.python-version"><code>.python-version</code></a> file with the correct python version specified and a <a href="grpc/Procfile"><code>Procfile</code></a> with correct entrypoint and arguments.</p>
</div>
<h3 id="deploy-locally-and-test_1">Deploy Locally and Test<a class="headerlink" href="#deploy-locally-and-test_1" title="Permanent link">&para;</a></h3>
<p>Launch the docker image built from last step with <code>buildpack</code>.
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>run<span class="w"> </span>-ePORT<span class="o">=</span><span class="m">8081</span><span class="w"> </span>-p8081:8081<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model-grpc:v1
</code></pre></div></p>
<p>Send a test inference request locally using <code>InferenceServerClient</code> <a href="grpc/grpc_client.py">grpc_client.py</a>
<div class="highlight"><span class="filename">grpc_client.py</span><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferRequest</span><span class="p">,</span> <span class="n">InferInput</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve.inference_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferenceGRPCClient</span>


<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">InferenceGRPCClient</span><span class="p">(</span>
        <span class="n">url</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INGRESS_HOST&quot;</span><span class="p">,</span> <span class="s2">&quot;localhost&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INGRESS_PORT&quot;</span><span class="p">,</span> <span class="s2">&quot;8081&quot;</span><span class="p">),</span>
        <span class="n">channel_args</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;grpc.ssl_target_name_override&#39;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SERVICE_HOSTNAME&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))]</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;../input.json&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_file</span><span class="p">)</span>
    <span class="n">infer_input</span> <span class="o">=</span> <span class="n">InferInput</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;input-0&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">datatype</span><span class="o">=</span><span class="s2">&quot;BYTES&quot;</span><span class="p">,</span>
                             <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="s2">&quot;b64&quot;</span><span class="p">])])</span>
    <span class="n">request</span> <span class="o">=</span> <span class="n">InferRequest</span><span class="p">(</span><span class="n">infer_inputs</span><span class="o">=</span><span class="p">[</span><span class="n">infer_input</span><span class="p">],</span> <span class="n">model_name</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;MODEL_NAME&quot;</span><span class="p">,</span> <span class="s2">&quot;custom-model&quot;</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="k">await</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">infer_request</span><span class="o">=</span><span class="n">request</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

<span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>grpc_client.py
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="highlight"><pre><span></span><code>&quot;id&quot;: &quot;b6a08abf-dcec-42ae-81af-084d9cad1c16&quot;,&quot;model_name&quot;: &quot;custom-model&quot;,&quot;outputs&quot;: [&quot;name&quot;: &quot;output-0&quot;,&quot;shape&quot;: [1, 5],&quot;datatype&quot;: &quot;FP32&quot;,&quot;data&quot;: [14.975618362426758, 14.036808967590332, 13.966032028198242, 12.252279281616211, 12.086268424987793],&quot;parameters&quot;: {}],&quot;parameters&quot;: {},&quot;from_grpc&quot;: True
</code></pre></div>
</div>
<h3 id="deploy-the-grpc-custom-serving-runtime-on-kserve">Deploy the gRPC Custom Serving Runtime on KServe<a class="headerlink" href="#deploy-the-grpc-custom-serving-runtime-on-kserve" title="Permanent link">&para;</a></h3>
<p>Create the InferenceService yaml and expose the gRPC port by specifying on <code>ports</code> section, currently only one port is allowed to expose and by default HTTP port is exposed.
<div class="highlight"><span class="filename">custom_grpc.yaml</span><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">custom-model-grpc</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-container</span>
<span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${DOCKER_USER}/custom-model-grpc:v1</span>
<span class="w">        </span><span class="nt">ports</span><span class="p">:</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">h2c</span>
<span class="w">            </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8081</span>
<span class="w">            </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TCP</span>
</code></pre></div>
In the <code>custom_grpc.yaml</code> file edit the container image and replace ${DOCKER_USER} with your Docker Hub username.</p>
<h4 id="arguments_1">Arguments<a class="headerlink" href="#arguments_1" title="Permanent link">&para;</a></h4>
<p>You can supply additional command arguments on the container spec to configure the model server.</p>
<ul>
<li><code>--grpc_port</code>: the http port model server is listening on, the default gRPC port is 8081.</li>
<li><code>--model_name</code>: the model name deployed in the model server, the default name the same as the service name.</li>
</ul>
<p>Apply the yaml to deploy the InferenceService on KServe</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">kubectl</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</div>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>custom_grpc.yaml
</code></pre></div>
<div class="admonition successs">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>$<span class="w"> </span>inferenceservice.serving.kserve.io/custom-model-grpc<span class="w"> </span>created
</code></pre></div>
</div>
<h3 id="run-a-grpc-prediction">Run a gRPC Prediction<a class="headerlink" href="#run-a-grpc-prediction" title="Permanent link">&para;</a></h3>
<p>The first step is to <a href="../../../../get_started/first_isvc/#4-determine-the-ingress-ip-and-ports">determine the ingress IP and ports</a> and set <code>INGRESS_HOST</code> and <code>INGRESS_PORT</code></p>
<div class="highlight"><pre><span></span><code><span class="nv">MODEL_NAME</span><span class="o">=</span>custom-model
<span class="nv">SERVICE_HOSTNAME</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>inferenceservice<span class="w"> </span>custom-model-grpc<span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.status.url}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="w"> </span><span class="s2">&quot;/&quot;</span><span class="w"> </span>-f<span class="w"> </span><span class="m">3</span><span class="k">)</span>
</code></pre></div>
<p>Send an inference request to the gRPC service using <code>InferenceServerClient</code> <a href="grpc/grpc_client.py">grpc_client.py</a>.</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>grpc_client.py
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="highlight"><pre><span></span><code>&quot;id&quot;: &quot;b6a08abf-dcec-42ae-81af-084d9cad1c16&quot;,&quot;model_name&quot;: &quot;custom-model&quot;,&quot;outputs&quot;: [&quot;name&quot;: &quot;output-0&quot;,&quot;shape&quot;: [1, 5],&quot;datatype&quot;: &quot;FP32&quot;,&quot;data&quot;: [14.975618362426758, 14.036808967590332, 13.966032028198242, 12.252279281616211, 12.086268424987793],&quot;parameters&quot;: {}],&quot;parameters&quot;: {},&quot;from_grpc&quot;: True
</code></pre></div>
</div>
<h2 id="parallel-model-inference">Parallel Model Inference<a class="headerlink" href="#parallel-model-inference" title="Permanent link">&para;</a></h2>
<p>By default, the models are loaded in the same process and inference is executed in the same process as the HTTP or gRPC server, if you are hosting multiple models the inference can only be run for one model at a time which limits the concurrency when you share the container for the models.
KServe integrates <a href="https://docs.ray.io/en/master/serve/index.html">RayServe</a> which provides a programmable API to deploy models
as separate python workers so, the inference can be performed in parallel when serving multiple custom models.</p>
<p><img alt="parallel_inference" src="parallel_inference.png" /></p>
<h3 id="setup_2">Setup<a class="headerlink" href="#setup_2" title="Permanent link">&para;</a></h3>
<ol>
<li>Install <a href="https://buildpacks.io/docs/tools/pack/">pack CLI</a> to build your custom model server image.</li>
<li><a href="./grpc">The code samples</a> can be found in the KServe website repository.</li>
</ol>
<div class="highlight"><span class="filename">model_remote.py</span><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">serve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelServer</span><span class="p">,</span> <span class="n">logging</span><span class="p">,</span> <span class="n">model_server</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve.ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">RayModel</span>


<span class="c1"># the model handle name should match the model endpoint name</span>
<span class="nd">@serve</span><span class="o">.</span><span class="n">deployment</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;custom-model&quot;</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AlexNetModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># The ready flag is used by model ready endpoint for readiness probes,</span>
        <span class="c1"># set to True when model is loaded successfully without exceptions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">headers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span>

        <span class="c1"># Input follows the Tensorflow V1 HTTP API for binary values</span>
        <span class="c1"># https://www.tensorflow.org/tfx/serving/api_rest#encoding_binary_values</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="s2">&quot;b64&quot;</span><span class="p">]</span>
        <span class="n">raw_img_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">raw_img_data</span><span class="p">))</span>
        <span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
                    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                <span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
        <span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">values</span><span class="p">,</span> <span class="n">top_5</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">model_server</span><span class="o">.</span><span class="n">parser</span><span class="p">])</span>
<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Configure kserve and uvicorn logger</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_config_file</span><span class="p">)</span>
    <span class="n">app</span> <span class="o">=</span> <span class="n">AlexNetModel</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">serve</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">app</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RayModel</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">handle</span><span class="o">=</span><span class="n">handle</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="n">ModelServer</span><span class="p">()</span><span class="o">.</span><span class="n">start</span><span class="p">([</span><span class="n">model</span><span class="p">])</span>
</code></pre></div>
<h3 id="fractional-gpu-example">Fractional GPU example<a class="headerlink" href="#fractional-gpu-example" title="Permanent link">&para;</a></h3>
<p><div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">serve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">ModelServer</span><span class="p">,</span> <span class="n">logging</span><span class="p">,</span> <span class="n">model_server</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve.ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">RayModel</span>


<span class="c1"># the model handle name should match the model endpoint name</span>
<span class="nd">@serve</span><span class="o">.</span><span class="n">deployment</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;custom-model&quot;</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ray_actor_options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;num_gpus&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">})</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AlexNetModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># The ready flag is used by model ready endpoint for readiness probes,</span>
        <span class="c1"># set to True when model is loaded successfully without exceptions.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">headers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">payload</span><span class="p">[</span><span class="s2">&quot;instances&quot;</span><span class="p">]</span>

        <span class="c1"># Input follows the Tensorflow V1 HTTP API for binary values</span>
        <span class="c1"># https://www.tensorflow.org/tfx/serving/api_rest#encoding_binary_values</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="s2">&quot;b64&quot;</span><span class="p">]</span>
        <span class="n">raw_img_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">raw_img_data</span><span class="p">))</span>
        <span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
                    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                <span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
        <span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">values</span><span class="p">,</span> <span class="n">top_5</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">model_server</span><span class="o">.</span><span class="n">parser</span><span class="p">])</span>
<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Configure kserve and uvicorn logger</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_config_file</span><span class="p">)</span>
    <span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">num_cpus</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">app</span> <span class="o">=</span> <span class="n">AlexNetModel</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">serve</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">app</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RayModel</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">handle</span><span class="o">=</span><span class="n">handle</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="n">ModelServer</span><span class="p">()</span><span class="o">.</span><span class="n">start</span><span class="p">([</span><span class="n">model</span><span class="p">])</span>
</code></pre></div>
The more details for ray fractional cpu and gpu can be found <a href="https://docs.ray.io/en/latest/serve/resource-allocation.html#fractional-cpus-and-fractional-gpus">here</a>.</p>
<h3 id="build-custom-serving-image-with-buildpacks_2">Build Custom Serving Image with BuildPacks<a class="headerlink" href="#build-custom-serving-image-with-buildpacks_2" title="Permanent link">&para;</a></h3>
<p>You can use pack cli to build the serving image which launches each model as separate python worker 
and web server routes to the model workers by name.
<div class="highlight"><pre><span></span><code>pack<span class="w"> </span>build<span class="w"> </span>--builder<span class="o">=</span>heroku/builder:24<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model-ray:v1
docker<span class="w"> </span>push<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model-ray:v1
</code></pre></div></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If your buildpack command fails, make sure you have a <a href="ray/.python-version"><code>.python-version</code></a> file with the correct python version specified and a <a href="ray/Procfile"><code>Procfile</code></a> with correct entrypoint and arguments.</p>
</div>
<h3 id="deploy-locally-and-test_2">Deploy Locally and Test<a class="headerlink" href="#deploy-locally-and-test_2" title="Permanent link">&para;</a></h3>
<p>Launch the docker image built from last step.
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>run<span class="w"> </span>-ePORT<span class="o">=</span><span class="m">8080</span><span class="w"> </span>-p8080:8080<span class="w"> </span><span class="si">${</span><span class="nv">DOCKER_USER</span><span class="si">}</span>/custom-model-ray:v1
</code></pre></div></p>
<p>Send a test inference request locally with <a href="input.json">input.json</a>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>localhost:8080/v1/models/custom-model:predict<span class="w"> </span>-d<span class="w"> </span>@./input.json
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code><span class="p">{</span><span class="nt">&quot;predictions&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="mf">14.861763000488281</span><span class="p">,</span><span class="w"> </span><span class="mf">13.94291877746582</span><span class="p">,</span><span class="w"> </span><span class="mf">13.924378395080566</span><span class="p">,</span><span class="w"> </span><span class="mf">12.182709693908691</span><span class="p">,</span><span class="w"> </span><span class="mf">12.00634765625</span><span class="p">]]}</span>
</code></pre></div>
</div>
<h2 id="configuring-logger-for-custom-serving-runtime">Configuring Logger for Custom Serving Runtime<a class="headerlink" href="#configuring-logger-for-custom-serving-runtime" title="Permanent link">&para;</a></h2>
<p>KServe allows users to override the default logger configuration of serving runtime and uvicorn server.
The logger configuration can be modified in one of the following ways:</p>
<h3 id="1-providing-logger-configuration-as-a-dict">1. Providing <a href="https://docs.python.org/3/library/logging.config.html#configuration-dictionary-schema">logger configuration as a Dict</a>:<a class="headerlink" href="#1-providing-logger-configuration-as-a-dict" title="Permanent link">&para;</a></h3>
<p>If you are building a custom serving runtime and want to modify the logger configuration, this method offers the easiest solution.
You can supply the logging configuration as a Python Dictionary to the <code>kserve.logging.configure_logging()</code> method. If the logging dictionary is not provided, KServe uses the default configuration <a href="https://github.com/kserve/kserve/blob/d19e31040c558ef88774736f67a0c2af7dbc6bc2/python/kserve/kserve/logging.py#L32">KSERVE_LOG_CONFIG</a>.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">kserve</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">logging</span>

<span class="c1">#################################</span>
<span class="c1">#       Source code             #</span>
<span class="c1">################################</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">kserve</span><span class="o">.</span><span class="n">model_server</span><span class="o">.</span><span class="n">parser</span><span class="p">])</span>
<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Example Dict config</span>
    <span class="n">dictConfig</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;version&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;disable_existing_loggers&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;formatters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;kserve&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;()&quot;</span><span class="p">:</span> <span class="s2">&quot;logging.Formatter&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fmt&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2">.</span><span class="si">%(msecs)03d</span><span class="s2"> </span><span class="si">%(filename)s</span><span class="s2">:</span><span class="si">%(funcName)s</span><span class="s2">():</span><span class="si">%(lineno)s</span><span class="s2"> </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;datefmt&quot;</span><span class="p">:</span> <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;kserve_trace&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;()&quot;</span><span class="p">:</span> <span class="s2">&quot;logging.Formatter&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fmt&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2">.</span><span class="si">%(msecs)03d</span><span class="s2"> </span><span class="si">%(name)s</span><span class="s2"> </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;datefmt&quot;</span><span class="p">:</span> <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;uvicorn&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;()&quot;</span><span class="p">:</span> <span class="s2">&quot;uvicorn.logging.DefaultFormatter&quot;</span><span class="p">,</span>
                <span class="s2">&quot;datefmt&quot;</span><span class="p">:</span> <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fmt&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2">.</span><span class="si">%(msecs)03d</span><span class="s2"> </span><span class="si">%(name)s</span><span class="s2"> </span><span class="si">%(levelprefix)s</span><span class="s2"> </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;use_colors&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;handlers&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;kserve&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;formatter&quot;</span><span class="p">:</span> <span class="s2">&quot;kserve&quot;</span><span class="p">,</span>
                <span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;logging.StreamHandler&quot;</span><span class="p">,</span>
                <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="s2">&quot;ext://sys.stderr&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;kserve_trace&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;formatter&quot;</span><span class="p">:</span> <span class="s2">&quot;kserve_trace&quot;</span><span class="p">,</span>
                <span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;logging.StreamHandler&quot;</span><span class="p">,</span>
                <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="s2">&quot;ext://sys.stderr&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;uvicorn&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;formatter&quot;</span><span class="p">:</span> <span class="s2">&quot;uvicorn&quot;</span><span class="p">,</span>
                <span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s2">&quot;logging.StreamHandler&quot;</span><span class="p">,</span>
                <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="s2">&quot;ext://sys.stderr&quot;</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;loggers&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;kserve&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;handlers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;kserve&quot;</span><span class="p">],</span>
                <span class="s2">&quot;level&quot;</span><span class="p">:</span> <span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
                <span class="s2">&quot;propagate&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;kserve.trace&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;handlers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;kserve_trace&quot;</span><span class="p">],</span>
                <span class="s2">&quot;level&quot;</span><span class="p">:</span> <span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
                <span class="s2">&quot;propagate&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;uvicorn&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;handlers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;uvicorn&quot;</span><span class="p">],</span> <span class="s2">&quot;level&quot;</span><span class="p">:</span> <span class="s2">&quot;INFO&quot;</span><span class="p">,</span> <span class="s2">&quot;propagate&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
        <span class="p">},</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">(</span><span class="n">dictConfig</span><span class="p">)</span>
</code></pre></div></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The logger should be configured before doing any actual work. A recommended best practice is to configure the logger
in the main, preferably as the first line of code. If the logger is configured later on in the source code, it may lead to
inconsistent logger formats.</p>
</div>
<h3 id="2-providing-logger-configuration-as-a-file">2. Providing logger configuration as a file:<a class="headerlink" href="#2-providing-logger-configuration-as-a-file" title="Permanent link">&para;</a></h3>
<p>The logger configuration can be provided as a file. If the filename ends with <code>.json</code>, KServe will treat the file as JSON Configuration.
If the filename ends with <code>.yaml</code> or <code>.yml</code>, KServe will treat the file as YAML Configuration. Otherwise, The file will be treated 
as a configuration file in the format specified in the <a href="https://docs.python.org/3/library/logging.config.html#configuration-file-format">Python logging module documentation</a>.
This offers a more flexible way of configuring the logger for pre-built serving runtimes.</p>
<p>The model server offers a command line argument which accepts a file path pointing to the configuration. For example,
<div class="highlight"><pre><span></span><code>sklearnserver<span class="w"> </span>--log_config_file<span class="o">=</span>/path/to/config.yaml
</code></pre></div>
For, Custom serving runtimes, they should accept the file path in their source code.
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">kserve</span><span class="w"> </span><span class="kn">import</span> <span class="n">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">kserve</span>

<span class="c1">#################################</span>
<span class="c1">#       Source code             #</span>
<span class="c1">################################</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">kserve</span><span class="o">.</span><span class="n">model_server</span><span class="o">.</span><span class="n">parser</span><span class="p">])</span>
<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_config_file</span><span class="p">)</span>
</code></pre></div>
Here is an example logging config in <code>JSON</code> format.
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;disable_existing_loggers&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;formatters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;kserve&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;()&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;logging.Formatter&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;fmt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;%(asctime)s.%(msecs)03d %(filename)s:%(funcName)s():%(lineno)s %(message)s&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;datefmt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;%Y-%m-%d %H:%M:%S&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;kserve_trace&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;()&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;logging.Formatter&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;fmt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;%(asctime)s.%(msecs)03d %(name)s %(message)s&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;datefmt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;%Y-%m-%d %H:%M:%S&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;uvicorn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;()&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;uvicorn.logging.DefaultFormatter&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;datefmt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;%Y-%m-%d %H:%M:%S&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;fmt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;%(asctime)s.%(msecs)03d %(name)s %(levelprefix)s %(message)s&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;use_colors&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;handlers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;kserve&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;formatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kserve&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;class&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;logging.StreamHandler&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;stream&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ext://sys.stderr&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;kserve_trace&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;formatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kserve_trace&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;class&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;logging.StreamHandler&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;stream&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ext://sys.stderr&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;uvicorn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;formatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;uvicorn&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;class&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;logging.StreamHandler&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;stream&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ext://sys.stderr&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;loggers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;kserve&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;handlers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="s2">&quot;kserve&quot;</span>
<span class="w">      </span><span class="p">],</span>
<span class="w">      </span><span class="nt">&quot;level&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;propagate&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;kserve.trace&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;handlers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="s2">&quot;kserve_trace&quot;</span>
<span class="w">      </span><span class="p">],</span>
<span class="w">      </span><span class="nt">&quot;level&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;propagate&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;uvicorn&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;handlers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="s2">&quot;uvicorn&quot;</span>
<span class="w">      </span><span class="p">],</span>
<span class="w">      </span><span class="nt">&quot;level&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;INFO&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;propagate&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div></p>
<p>Here is an example using <code>YAML</code> format for configuring logger.
<div class="highlight"><pre><span></span><code><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">disable_existing_loggers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">formatters</span><span class="p">:</span>
<span class="w">  </span><span class="nt">kserve</span><span class="p">:</span>
<span class="w">    </span><span class="s">&quot;()&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">logging.Formatter</span>
<span class="w">    </span><span class="nt">fmt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;%(asctime)s.%(msecs)03d</span><span class="nv"> </span><span class="s">%(filename)s:%(funcName)s():%(lineno)s</span><span class="nv"> </span><span class="s">%(message)s&quot;</span>
<span class="w">    </span><span class="nt">datefmt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;%Y-%m-%d</span><span class="nv"> </span><span class="s">%H:%M:%S&quot;</span>
<span class="w">  </span><span class="nt">kserve_trace</span><span class="p">:</span>
<span class="w">    </span><span class="s">&quot;()&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">logging.Formatter</span>
<span class="w">    </span><span class="nt">fmt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;%(asctime)s.%(msecs)03d</span><span class="nv"> </span><span class="s">%(name)s</span><span class="nv"> </span><span class="s">%(message)s&quot;</span>
<span class="w">    </span><span class="nt">datefmt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;%Y-%m-%d</span><span class="nv"> </span><span class="s">%H:%M:%S&quot;</span>
<span class="w">  </span><span class="nt">uvicorn</span><span class="p">:</span>
<span class="w">    </span><span class="s">&quot;()&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">uvicorn.logging.DefaultFormatter</span>
<span class="w">    </span><span class="nt">datefmt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;%Y-%m-%d</span><span class="nv"> </span><span class="s">%H:%M:%S&quot;</span>
<span class="w">    </span><span class="nt">fmt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;%(asctime)s.%(msecs)03d</span><span class="nv"> </span><span class="s">%(name)s</span><span class="nv"> </span><span class="s">%(levelprefix)s</span><span class="nv"> </span><span class="s">%(message)s&quot;</span>
<span class="w">    </span><span class="nt">use_colors</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">handlers</span><span class="p">:</span>
<span class="w">  </span><span class="nt">kserve</span><span class="p">:</span>
<span class="w">    </span><span class="nt">formatter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">logging.StreamHandler</span>
<span class="w">    </span><span class="nt">stream</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ext://sys.stderr</span>
<span class="w">  </span><span class="nt">kserve_trace</span><span class="p">:</span>
<span class="w">    </span><span class="nt">formatter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve_trace</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">logging.StreamHandler</span>
<span class="w">    </span><span class="nt">stream</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ext://sys.stderr</span>
<span class="w">  </span><span class="nt">uvicorn</span><span class="p">:</span>
<span class="w">    </span><span class="nt">formatter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">uvicorn</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">logging.StreamHandler</span>
<span class="w">    </span><span class="nt">stream</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ext://sys.stderr</span>
<span class="nt">loggers</span><span class="p">:</span>
<span class="w">  </span><span class="nt">kserve</span><span class="p">:</span>
<span class="w">    </span><span class="nt">handlers</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve</span>
<span class="w">    </span><span class="nt">level</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">INFO</span>
<span class="w">    </span><span class="nt">propagate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">  </span><span class="nt">kserve.trace</span><span class="p">:</span>
<span class="w">    </span><span class="nt">handlers</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve_trace</span>
<span class="w">    </span><span class="nt">level</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">INFO</span>
<span class="w">    </span><span class="nt">propagate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">  </span><span class="nt">uvicorn</span><span class="p">:</span>
<span class="w">    </span><span class="nt">handlers</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">uvicorn</span>
<span class="w">    </span><span class="nt">level</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">INFO</span>
<span class="w">    </span><span class="nt">propagate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</code></pre></div>
For other file formats, Please refer <a href="https://docs.python.org/3/library/logging.config.html#configuration-file-format">Python docs</a>.</p>
<h3 id="3-disabling-logger-configuration">3. Disabling logger Configuration:<a class="headerlink" href="#3-disabling-logger-configuration" title="Permanent link">&para;</a></h3>
<p>If you don't want Kserve to configure the logger then, You can disable it by passing the commandline argument <code>--configure_logging=False</code> 
to the model server. The command line argument <code>--log_config_file</code> will be ignored, if the logger configuration is disabled.
In this case, the logger will inherit the root logger's configuration.</p>
<div class="highlight"><pre><span></span><code>sklearnserver<span class="w"> </span>--configure_logging<span class="o">=</span>False
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the logger is not configured at the entrypoint in the serving runtime (i.e. logging.configure_logger() is not invoked),
The model server will configure the logger using default configuration. But note that the logger is configured at 
model server initialization. So any logs before the initialization will use the root logger's configuration.</p>
</div>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../../amd/" class="md-footer__link md-footer__link--prev" aria-label="Previous: AMD" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              AMD
            </div>
          </div>
        </a>
      
      
        
        <a href="../../../mms/multi-model-serving/" class="md-footer__link md-footer__link--next" aria-label="Next: The Scalability Problem" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              The Scalability Problem
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright  2021 The KServe Authors
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    <a href="https://github.com/kserve" target="_blank" rel="noopener" title="KServe Community on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    <a href="https://github.com/kserve/community/blob/main/README.md#questions-and-issues" target="_blank" rel="noopener" title="Join Slack" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.tracking", "navigation.tabs.sticky", "navigation.top"], "search": "../../../../assets/javascripts/workers/search.cefbb252.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.a5f8ea78.min.js"></script>
      
    
  </body>
</html>