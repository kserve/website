
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="KServe Documentation">
      
      
      
        <link rel="canonical" href="https://kserve.io/website/master/modelserving/v1beta1/llm/huggingface/multi-node/">
      
      <link rel="icon" href="../../../../../images/favicon/favicon-32x32.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-8.0.5">
    
    
      
        <title>Multi Node Inference - KServe Documentation Website</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.a617204b.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.9204c3b2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#multi-nodemulti-gpu-inference-with-hugging-face-vllm-serving-runtime" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
 <h1>
   <b>KServe v0.15 is Released</b>, <a href="/website/0.15/blog/articles/2025-05-27-KServe-0.15-release/">Read blog &gt;&gt;</a>
 </h1>

          </div>
        </aside>
      
    </div>
    
      <div data-md-component="outdated" hidden>
        <aside class="md-banner md-banner--warning">
          
        </aside>
      </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="KServe Documentation Website" class="md-header__button md-logo" aria-label="KServe Documentation Website" data-md-component="logo">
      
  <img src="../../../../../images/logo/kserve.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            KServe Documentation Website
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Multi Node Inference
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/kserve/kserve" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../get_started/" class="md-tabs__link">
        Getting started
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../admin/serverless/serverless/" class="md-tabs__link">
        Administration Guide
      </a>
    </li>
  

  

  

      
        
  
  
    
  


  
  
  
    

  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../../control_plane/" class="md-tabs__link md-tabs__link--active">
        User Guide
      </a>
    </li>
  

  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../reference/api/" class="md-tabs__link">
        API Reference
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../developer/developer/" class="md-tabs__link">
        Developer Guide
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../blog/articles/2025-05-27-KServe-0.15-release/" class="md-tabs__link">
        Blog
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../community/get_involved/" class="md-tabs__link">
        Community
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="KServe Documentation Website" class="md-nav__button md-logo" aria-label="KServe Documentation Website" data-md-component="logo">
      
  <img src="../../../../../images/logo/kserve.png" alt="logo">

    </a>
    KServe Documentation Website
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/kserve/kserve" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Getting started
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Getting started" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Getting started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../get_started/" class="md-nav__link">
        KServe Quickstart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../get_started/first_isvc/" class="md-nav__link">
        First InferenceService
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../get_started/swagger_ui/" class="md-nav__link">
        Interact with InferenceService Swagger UI
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Administration Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Administration Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Administration Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          Install KServe
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Install KServe" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Install KServe
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_1" type="checkbox" id="__nav_3_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1">
          Predictive Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Inference" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          Predictive Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/serverless/serverless/" class="md-nav__link">
        Serverless installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/kubernetes_deployment/" class="md-nav__link">
        Kubernetes deployment installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/modelmesh/" class="md-nav__link">
        ModelMesh installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/serverless/kourier_networking/" class="md-nav__link">
        Kourier Networking Layer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_2" type="checkbox" id="__nav_3_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2">
          Generative Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Generative Inference" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Generative Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/kubernetes_deployment/" class="md-nav__link">
        Kubernetes deployment installation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/ai-gateway_integration/" class="md-nav__link">
        AI Gateway Integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/serverless/servicemesh/" class="md-nav__link">
        Istio Service Mesh
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/gatewayapi_migration/" class="md-nav__link">
        Gateway API migration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          User Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1">
          Concepts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Concepts" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_1" type="checkbox" id="__nav_4_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_1">
          Control Plane
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Control Plane" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_1">
          <span class="md-nav__icon md-icon"></span>
          Control Plane
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../control_plane/" class="md-nav__link">
        Model Serving Control Plane
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_2" type="checkbox" id="__nav_4_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_2">
          Data Plane
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Data Plane" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_2">
          <span class="md-nav__icon md-icon"></span>
          Data Plane
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../data_plane/data_plane/" class="md-nav__link">
        Model Serving Data Plane
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../data_plane/v1_protocol/" class="md-nav__link">
        V1 Inference Protocol
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../data_plane/v2_protocol/" class="md-nav__link">
        Open Inference Protocol (V2 Inference Protocol)
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_2_4" type="checkbox" id="__nav_4_1_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_2_4">
          Open Inference Protocol Extensions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Open Inference Protocol Extensions" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_1_2_4">
          <span class="md-nav__icon md-icon"></span>
          Open Inference Protocol Extensions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../data_plane/binary_tensor_data_extension/" class="md-nav__link">
        Binary Tensor Data Extension
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../servingruntimes/" class="md-nav__link">
        Serving Runtimes
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Generative Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Generative Inference" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Generative Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_1" type="checkbox" id="__nav_4_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_1">
          Serving Runtime
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Serving Runtime" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_1">
          <span class="md-nav__icon md-icon"></span>
          Serving Runtime
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../text_generation/" class="md-nav__link">
        Text Generation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../text2text_generation/" class="md-nav__link">
        Text2Text Generation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sdk_integration/" class="md-nav__link">
        OpenAI SDK Integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Multi Node Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Multi Node Inference
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#restrictions" class="md-nav__link">
    Restrictions
  </a>
  
    <nav class="md-nav" aria-label="Restrictions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-validations" class="md-nav__link">
    Key Validations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consideration" class="md-nav__link">
    Consideration
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workerspec-and-servingruntime" class="md-nav__link">
    WorkerSpec and ServingRuntime
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-configurations" class="md-nav__link">
    Key Configurations
  </a>
  
    <nav class="md-nav" aria-label="Key Configurations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-inferenceservice" class="md-nav__link">
    Example InferenceService
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#serve-the-hugging-face-vllm-model-using-2-nodes" class="md-nav__link">
    Serve the Hugging Face vLLM Model Using 2 Nodes
  </a>
  
    <nav class="md-nav" aria-label="Serve the Hugging Face vLLM Model Using 2 Nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-create-a-persistent-volume-claim-pvc" class="md-nav__link">
    1. Create a Persistent Volume Claim (PVC)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-download-the-model-to-the-pvc" class="md-nav__link">
    2. Download the Model to the PVC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-create-a-servingruntime" class="md-nav__link">
    3. Create a ServingRuntime
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-deploy-the-model" class="md-nav__link">
    4. Deploy the model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#check-inferenceservice-status" class="md-nav__link">
    Check InferenceService status.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#check-gpu-resource-status" class="md-nav__link">
    Check GPU resource status.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#perform-model-inference" class="md-nav__link">
    Perform Model Inference
  </a>
  
    <nav class="md-nav" aria-label="Perform Model Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sample-openai-completions-request" class="md-nav__link">
    Sample OpenAI Completions request:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sample-openai-chat-request" class="md-nav__link">
    Sample OpenAI Chat request:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/modelcache/localmodel/" class="md-nav__link">
        Model Cache
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../autoscaling/keda/autoscaling_llm/" class="md-nav__link">
        LLM Autoscaler
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../kv_cache_offloading/" class="md-nav__link">
        KV Cache Offloading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../admin/ai-gateway_integration/" class="md-nav__link">
        AI Gateway Integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          Predictive Inference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Inference" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Predictive Inference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1" type="checkbox" id="__nav_4_3_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1">
          Model Serving Runtimes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Serving Runtimes" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_1">
          <span class="md-nav__icon md-icon"></span>
          Model Serving Runtimes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_1" type="checkbox" id="__nav_4_3_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_1">
          Supported Model Frameworks/Formats
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Supported Model Frameworks/Formats" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          Supported Model Frameworks/Formats
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../serving_runtime/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../tensorflow/" class="md-nav__link">
        Tensorflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../torchserve/" class="md-nav__link">
        PyTorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../sklearn/v2/" class="md-nav__link">
        Scikit-learn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../xgboost/" class="md-nav__link">
        XGBoost
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../pmml/" class="md-nav__link">
        PMML
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../spark/" class="md-nav__link">
        Spark MLlib
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../lightgbm/" class="md-nav__link">
        LightGBM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../paddle/" class="md-nav__link">
        Paddle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../mlflow/v2/" class="md-nav__link">
        MLFlow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../onnx/" class="md-nav__link">
        ONNX
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_1_12" type="checkbox" id="__nav_4_3_1_1_12" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_1_12">
          Hugging Face
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Hugging Face" data-md-level="5">
        <label class="md-nav__title" for="__nav_4_3_1_1_12">
          <span class="md-nav__icon md-icon"></span>
          Hugging Face
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../huggingface/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../huggingface/token_classification/" class="md-nav__link">
        Token Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../huggingface/text_classification/" class="md-nav__link">
        Text Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../huggingface/fill_mask/" class="md-nav__link">
        Fill Mask
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_2" type="checkbox" id="__nav_4_3_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_2">
          Multi-Framework Serving Runtimes
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Multi-Framework Serving Runtimes" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Multi-Framework Serving Runtimes
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1_2_1" type="checkbox" id="__nav_4_3_1_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_1_2_1">
          Nvidia Triton
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Nvidia Triton" data-md-level="5">
        <label class="md-nav__title" for="__nav_4_3_1_2_1">
          <span class="md-nav__icon md-icon"></span>
          Nvidia Triton
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../triton/torchscript/" class="md-nav__link">
        TorchScript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../triton/bert/" class="md-nav__link">
        Tensorflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../triton/huggingface/" class="md-nav__link">
        Hugging Face
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../amd/" class="md-nav__link">
        AMD
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../custom/custom_model/" class="md-nav__link">
        How to write a custom predictor
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_2" type="checkbox" id="__nav_4_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2">
          Multi Model Serving
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Multi Model Serving" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_2">
          <span class="md-nav__icon md-icon"></span>
          Multi Model Serving
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_2_1" type="checkbox" id="__nav_4_3_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2_1">
          Overview
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Overview" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          Overview
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mms/multi-model-serving/" class="md-nav__link">
        The Scalability Problem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../mms/modelmesh/overview/" class="md-nav__link">
        ModelMesh Overview
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_3" type="checkbox" id="__nav_4_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_3">
          Transformers(pre/post processing)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Transformers(pre/post processing)" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_3">
          <span class="md-nav__icon md-icon"></span>
          Transformers(pre/post processing)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformer/torchserve_image_transformer/" class="md-nav__link">
        How to write a custom transformer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformer/collocation/" class="md-nav__link">
        Collocate transformer and predictor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformer/feast/" class="md-nav__link">
        Feast
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_4" type="checkbox" id="__nav_4_3_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_4">
          Rollout Strategies
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Rollout Strategies" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_4">
          <span class="md-nav__icon md-icon"></span>
          Rollout Strategies
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../rollout/canary/" class="md-nav__link">
        Canary
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../rollout/canary-example/" class="md-nav__link">
        Canary Example
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_5" type="checkbox" id="__nav_4_3_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_5">
          Autoscaling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Autoscaling" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_5">
          <span class="md-nav__icon md-icon"></span>
          Autoscaling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../autoscaling/autoscaling/" class="md-nav__link">
        Knative Autoscaler(KPA)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../autoscaling/raw_deployment_autoscaling/" class="md-nav__link">
        Kubernetes Autoscaler(HPA)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../autoscaling/keda/autoscaling_keda/" class="md-nav__link">
        KEDA Autoscaler
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_6" type="checkbox" id="__nav_4_3_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_6">
          Request Batching
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Request Batching" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_6">
          <span class="md-nav__icon md-icon"></span>
          Request Batching
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../batcher/batcher/" class="md-nav__link">
        Inference Batcher
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_7" type="checkbox" id="__nav_4_3_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_7">
          Payload Logging
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Payload Logging" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_7">
          <span class="md-nav__icon md-icon"></span>
          Payload Logging
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../logger/logger/" class="md-nav__link">
        Inference Logger
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_8" type="checkbox" id="__nav_4_3_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_8">
          Kafka
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Kafka" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_8">
          <span class="md-nav__icon md-icon"></span>
          Kafka
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../kafka/kafka/" class="md-nav__link">
        Inference with Kafka Event Source
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_9" type="checkbox" id="__nav_4_3_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_9">
          Inference Observability
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Inference Observability" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_9">
          <span class="md-nav__icon md-icon"></span>
          Inference Observability
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../observability/prometheus_metrics/" class="md-nav__link">
        Prometheus Metrics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../observability/grafana_dashboards/" class="md-nav__link">
        Grafana Dashboards
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_10" type="checkbox" id="__nav_4_3_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_10">
          Model Explainability
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Explainability" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_10">
          <span class="md-nav__icon md-icon"></span>
          Model Explainability
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../explainer/explainer/" class="md-nav__link">
        Concept
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../explainer/trustyai/" class="md-nav__link">
        TrustyAI Explainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_10_3" type="checkbox" id="__nav_4_3_10_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_10_3">
          Alibi Explainer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Alibi Explainer" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_3_10_3">
          <span class="md-nav__icon md-icon"></span>
          Alibi Explainer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../explainer/alibi/cifar10/" class="md-nav__link">
        Image Explainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../explainer/alibi/income/" class="md-nav__link">
        Income Explainer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../explainer/alibi/moviesentiment/" class="md-nav__link">
        Text Explainer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../explainer/aix/mnist/aix/" class="md-nav__link">
        AIX Explainer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_11" type="checkbox" id="__nav_4_3_11" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_11">
          Model Monitoring
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Monitoring" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_11">
          <span class="md-nav__icon md-icon"></span>
          Model Monitoring
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../detect/alibi_detect/alibi_detect/" class="md-nav__link">
        Alibi Detector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../detect/aif/germancredit/" class="md-nav__link">
        AIF Bias Detector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../detect/art/mnist/" class="md-nav__link">
        ART Adversarial Detector
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_4" type="checkbox" id="__nav_4_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_4">
          Inference Graph
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Inference Graph" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Inference Graph
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../inference_graph/" class="md-nav__link">
        Concept
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../inference_graph/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../inference_graph/image_pipeline/" class="md-nav__link">
        Image classification inference graph
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_5" type="checkbox" id="__nav_4_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_5">
          Model Storage
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Storage" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_5">
          <span class="md-nav__icon md-icon"></span>
          Model Storage
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/storagecontainers/" class="md-nav__link">
        Storage Containers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../certificate/kserve/" class="md-nav__link">
        Configure CA Certificate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/azure/azure/" class="md-nav__link">
        Azure
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/pvc/pvc/" class="md-nav__link">
        PVC
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/s3/s3/" class="md-nav__link">
        S3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/oci/" class="md-nav__link">
        OCI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/uri/uri/" class="md-nav__link">
        URI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/gcs/gcs/" class="md-nav__link">
        GCS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../storage/huggingface/hf/" class="md-nav__link">
        Hugging Face
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_6" type="checkbox" id="__nav_4_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_6">
          Node Scheduling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Node Scheduling" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_6">
          <span class="md-nav__icon md-icon"></span>
          Node Scheduling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../nodescheduling/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../nodescheduling/inferenceservicenodescheduling/" class="md-nav__link">
        InferenceService Node Scheduling
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../reference/api/" class="md-nav__link">
        Control Plane API
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../reference/swagger-ui/" class="md-nav__link">
        Open Inference Protocol API Spec
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../sdk_docs/sdk_doc/" class="md-nav__link">
        Python Client SDK
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../python_runtime_api/docs/" class="md-nav__link">
        Python Runtime Server SDK
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../inference_client/doc/" class="md-nav__link">
        Inference Python Client
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Developer Guide
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Developer Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Developer Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../developer/developer/" class="md-nav__link">
        How to contribute
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../developer/debug/" class="md-nav__link">
        Debugging guide
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Blog
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Blog" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Blog
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1" type="checkbox" id="__nav_7_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_1">
          Releases
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Releases" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_1">
          <span class="md-nav__icon md-icon"></span>
          Releases
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2025-05-27-KServe-0.15-release/" class="md-nav__link">
        KServe 0.15 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2024-12-13-KServe-0.14-release/" class="md-nav__link">
        KServe 0.14 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2024-05-15-KServe-0.13-release/" class="md-nav__link">
        KServe 0.13 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2023-10-08-KServe-0.11-release/" class="md-nav__link">
        KServe 0.11 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2023-02-05-KServe-0.10-release/" class="md-nav__link">
        KServe 0.10 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2022-07-21-KServe-0.9-release/" class="md-nav__link">
        KServe 0.9 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2022-02-18-KServe-0.8-release/" class="md-nav__link">
        KServe 0.8 Release
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../blog/articles/2021-10-11-KServe-0.7-release/" class="md-nav__link">
        KServe 0.7 Release
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" type="checkbox" id="__nav_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_8">
          Community
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Community" data-md-level="1">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Community
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../community/get_involved/" class="md-nav__link">
        How to Get Involved
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../community/adopters/" class="md-nav__link">
        Adopters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../community/presentations/" class="md-nav__link">
        Demos and Presentations
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#restrictions" class="md-nav__link">
    Restrictions
  </a>
  
    <nav class="md-nav" aria-label="Restrictions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-validations" class="md-nav__link">
    Key Validations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consideration" class="md-nav__link">
    Consideration
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workerspec-and-servingruntime" class="md-nav__link">
    WorkerSpec and ServingRuntime
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-configurations" class="md-nav__link">
    Key Configurations
  </a>
  
    <nav class="md-nav" aria-label="Key Configurations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-inferenceservice" class="md-nav__link">
    Example InferenceService
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#serve-the-hugging-face-vllm-model-using-2-nodes" class="md-nav__link">
    Serve the Hugging Face vLLM Model Using 2 Nodes
  </a>
  
    <nav class="md-nav" aria-label="Serve the Hugging Face vLLM Model Using 2 Nodes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-create-a-persistent-volume-claim-pvc" class="md-nav__link">
    1. Create a Persistent Volume Claim (PVC)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-download-the-model-to-the-pvc" class="md-nav__link">
    2. Download the Model to the PVC
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-create-a-servingruntime" class="md-nav__link">
    3. Create a ServingRuntime
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-deploy-the-model" class="md-nav__link">
    4. Deploy the model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#check-inferenceservice-status" class="md-nav__link">
    Check InferenceService status.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#check-gpu-resource-status" class="md-nav__link">
    Check GPU resource status.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#perform-model-inference" class="md-nav__link">
    Perform Model Inference
  </a>
  
    <nav class="md-nav" aria-label="Perform Model Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sample-openai-completions-request" class="md-nav__link">
    Sample OpenAI Completions request:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sample-openai-chat-request" class="md-nav__link">
    Sample OpenAI Chat request:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/kserve/website/edit/main/docs/modelserving/v1beta1/llm/huggingface/multi-node/README.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>


<h1 id="multi-nodemulti-gpu-inference-with-hugging-face-vllm-serving-runtime">Multi-node/Multi-GPU Inference with Hugging Face vLLM Serving Runtime<a class="headerlink" href="#multi-nodemulti-gpu-inference-with-hugging-face-vllm-serving-runtime" title="Permanent link">&para;</a></h1>
<p>This guide provides step-by-step instructions on setting up multi-node and multi-GPU inference using Hugging Face's vLLM Serving Runtime. Before proceeding, please ensure you meet the following prerequisites and understand the limitations of this setup.</p>
<h2 id="restrictions">Restrictions<a class="headerlink" href="#restrictions" title="Permanent link">&para;</a></h2>
<ul>
<li>Multi-node functionality is only supported in <strong>RawDeployment</strong> mode.</li>
<li><strong>Auto-scaling is not available</strong> for multi-node setups. </li>
<li>A <strong>Persistent Volume Claim (PVC)</strong> is required for multi-node configurations, and it must support the <strong>ReadWriteMany (RWX)</strong> access mode.</li>
</ul>
<h3 id="key-validations">Key Validations<a class="headerlink" href="#key-validations" title="Permanent link">&para;</a></h3>
<ul>
<li><code>TENSOR_PARALLEL_SIZE</code> and <code>PIPELINE_PARALLEL_SIZE</code> cannot be set via environment variables. They must be configured through <code>workerSpec.tensorParallelSize</code> and <code>workerSpec.pipelineParallelSize</code> respectively.</li>
<li>In the <code>ServingRuntime</code>, default values for <code>workerSpec.tensorParallelSize</code> and <code>workerSpec.pipelineParallelSize</code> are <code>1</code> and <code>1</code> respectively.<br />
  These values <strong>can be overridden</strong> by the InferenceService.</li>
<li>Currently, four GPU types are allowed: <code>nvidia.com/gpu</code> (<em>default</em>), <code>intel.com/gpu</code>, <code>amd.com/gpu</code>, and <code>habana.ai/gaudi</code>.<ul>
<li>If you want to use other GPU types, you can set this in the annotations of ISVC as follows:
  <div class="highlight"><pre><span></span><code>serving.kserve.io/gpu-resource-types: &#39;[&quot;nvidia.com/mig-1g.5gb&quot;, &quot;nvidia.com/mig-2g.10gb&quot;, &quot;gpu-type3&quot;]&#39;
</code></pre></div><blockquote>
<p>Note: vLLM distributed inference only supports nccl for now.</p>
</blockquote>
</li>
</ul>
</li>
<li>You can specify the GPU type via InferenceService, but if it differs from what is set in the ServingRuntime, both GPU types will be assigned to the resource. <strong>Then it can cause issues.</strong></li>
<li>The Autoscaler must be configured as <code>none</code>.</li>
<li>The only supported storage protocol for StorageURI is <code>PVC</code>.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You must have <strong>exactly one head pod</strong> in your setup. The replica count for this head pod can be adjusted using the <code>min_replicas</code> or <code>max_replicas</code> settings in the <code>InferenceService (ISVC)</code>. However, creating additional head pods will cause them to be excluded from the Ray cluster, resulting in improper functioning. Ensure this limitation is clearly documented.</p>
<p>Do not use 2 different GPU types for multi node serving.</p>
</div>
<h3 id="consideration">Consideration<a class="headerlink" href="#consideration" title="Permanent link">&para;</a></h3>
<p>Using the multi-node feature likely indicates that you are trying to deploy a very large model. In such cases, you should consider increasing the <code>initialDelaySeconds</code> for the <code>livenessProbe</code>, <code>readinessProbe</code>, and <code>startupProbe</code>. The default values may not be suitable for your specific needs. </p>
<p>You can set StartupProbe in ServingRuntime for your own situation.</p>
<p><em>default setup:</em>
<div class="highlight"><pre><span></span><code>..
      startupProbe:
        failureThreshold: 40
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 30
        initialDelaySeconds: 60
..
</code></pre></div></p>
<p>Multi-node setups typically use the <code>RollingUpdate</code> deployment strategy, which ensures that the existing service remains operational until the new service becomes Ready. However, this approach requires more than twice the resources to function effectively. Therefore, during the development phase, it is more appropriate to use the <code>Recreate</code> strategy.</p>
<p><div class="highlight"><pre><span></span><code>spec:
  predictor:
    deploymentStrategy:
      type: Recreate
    model:
      modelFormat:
        name: huggingface
      runtime: kserve-huggingfaceserver-multinode
      storageUri: pvc://XXXX
    workerSpec: {}
</code></pre></div>
Additionally, modifying the <code>PipelineParallelSize</code> (either increasing or decreasing it) can impact the existing service due to the default behavior of the Deployment resource. It is important to note that <strong>PipelineParallelSize is not an autoscaling concept</strong>; rather, it determines how many nodes will be used to run the model. For this reason, it is strongly recommended not to modify this setting in production environments.</p>
<p>If the <code>Recreate</code> deployment strategy is not used and you need to change the PipelineParallelSize, the best approach is to delete the existing InferenceService (ISVC) and create a new one with the desired configuration. The same recommendation applies to TensorParallelSize, as modifying this setting dynamically can also affect the service's stability and performance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To reiterate, <strong>PipelineParallelSize is not a general-purpose autoscaling mechanism</strong>, and changes to it should be handled with caution, especially in production environments.</p>
</div>
<h2 id="workerspec-and-servingruntime">WorkerSpec and ServingRuntime<a class="headerlink" href="#workerspec-and-servingruntime" title="Permanent link">&para;</a></h2>
<p>To enable multi-node/multi-GPU inference,  <code>workerSpec</code> must be configured in both ServingRuntime and InferenceService. The <code>huggingface-server-multinode</code> <code>ServingRuntime</code> already includes this field and is built on <strong>vLLM</strong>, which supports multi-node/multi-GPU feature. Note that this setup is <strong>not compatible with Triton</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Even if the <code>ServingRuntime</code> is properly configured with <code>workerSpec</code>, multi-node/multi-GPU will not be enabled unless the InferenceService also configures the workerSpec.</p>
</div>
<div class="highlight"><pre><span></span><code>...
  predictor:
    model:
      runtime: kserve-huggingfaceserver-multinode
      modelFormat:
        name: huggingface
      storageUri: pvc://llama-3-8b-pvc/hf/8b_instruction_tuned  
    workerSpec: {} # Specifying workerSpec indicates that multi-node functionality will be used     
</code></pre></div>
<h2 id="key-configurations">Key Configurations<a class="headerlink" href="#key-configurations" title="Permanent link">&para;</a></h2>
<p>The <code>huggingface-server-multinode</code> <code>ServingRuntime</code> leverages the distributed inference capability provided by vLLM.<br />
However, the official <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">vLLM documentation</a> describes distributed inference based on a <strong>physical environment</strong>. In contrast, <strong>Kubernetes</strong> works quite differently. Therefore, it's important to understand how GPU allocation works in <strong>KServe</strong> when using this <code>ServingRuntime</code>.</p>
<p>When using the <code>huggingface-server-multinode</code> <code>ServingRuntime</code>, there are two critical configurations to understand:</p>
<ol>
<li>
<p><strong><code>workerSpec.tensorParallelSize</code></strong><br />
   From the <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">vLLM documentation</a>:  </p>
<blockquote>
<p>The tensor parallel size is the number of GPUs you want to use in each node</p>
</blockquote>
<p>In <strong>KServe</strong>, <code>tensorParallelSize</code> does <strong>not</strong> directly map to the number of GPUs.<br />
Instead, this value is <strong>only</strong> used to configure <strong>tensor parallelism</strong>that is, how the model <strong>weights</strong> are sharded across GPUs.</p>
</li>
<li>
<p><strong><code>workerSpec.pipelineParallelSize</code></strong><br />
   From the <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html">vLLM documentation</a>:  </p>
<blockquote>
<p>The pipeline parallel size is the number of nodes</p>
</blockquote>
<p>In <strong>KServe</strong>, <code>pipelineParallelSize</code> also does <strong>not</strong> correspond 1:1 with the number of Kubernetes nodes.<br />
Instead, it is <strong>only</strong> used to configure <strong>pipeline parallelism</strong>how the model <strong>layers</strong> are split across the GPUs.</p>
</li>
</ol>
<h3 id="example-inferenceservice">Example InferenceService<a class="headerlink" href="#example-inferenceservice" title="Permanent link">&para;</a></h3>
<p>Heres an example of an <code>InferenceService</code> configuration for a Hugging Face model:</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">huggingface-llama3</span>
<span class="w">  </span><span class="nt">annotations</span><span class="p">:</span>
<span class="w">    </span><span class="nt">serving.kserve.io/deploymentMode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">RawDeployment</span>
<span class="w">    </span><span class="nt">serving.kserve.io/autoscalerClass</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">none</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">model</span><span class="p">:</span>
<span class="w">      </span><span class="nt">modelFormat</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">huggingface</span>
<span class="w">      </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pvc://llama-3-8b-pvc/hf/8b_instruction_tuned</span>
<span class="w">    </span><span class="nt">workerSpec</span><span class="p">:</span>
<span class="w">      </span><span class="nt">pipelineParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">tensorParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Mechanism: How to Set GPU Allocation per Node</p>
<div class="highlight"><pre><span></span><code>Total GPUs = tensorParallelSize  pipelineParallelSize

Ray Node Count = ceil(Total GPUs / workerSpec.resources.requests.gpu)
Worker GPU Count = (Total GPUs / Ray Node Count) - 1
Head GPU Count = Total GPUs - 1

# If Total GPUs == workerSpec.resources.requests.gpu, only the head node will be deployed.
</code></pre></div>
<p><strong>Environment</strong>: 16 GPUs across 2 nodes (8 GPUs per node)</p>
<hr />
<p><strong>Case 1: <code>pipelineParallelSize = 2</code>, <code>tensorParallelSize = 8</code>, <code>workerSpec.resources.requests.gpu = 8</code></strong></p>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>/path/to/the/model/in/the/container<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--tensor-parallel-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--pipeline-parallel-size<span class="w"> </span><span class="m">2</span>
</code></pre></div>
<p>According to the vLLM documentation, this configuration requires 16 GPUs.<br />
If all GPUs are available, it should assign 8 GPUs to each of 2 Pods.</p>
<p>Example configuration:</p>
<div class="highlight"><pre><span></span><code><span class="nt">workerSpec</span><span class="p">:</span><span class="w">    </span>
<span class="w">  </span><span class="nt">pipelineParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">  </span><span class="nt">tensorParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">worker-container</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;8&quot;</span>
</code></pre></div>
<hr />
<p><strong>Case 2: No <code>pipelineParallelSize</code>, <code>tensorParallelSize = 16</code>, <code>workerSpec.resources.requests.gpu = 8</code></strong></p>
<div class="highlight"><pre><span></span><code>vllm<span class="w"> </span>serve<span class="w"> </span>/path/to/the/model/in/the/container<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--tensor-parallel-size<span class="w"> </span><span class="m">16</span>
</code></pre></div>
<p>This also requires 16 GPUs. To meet this, KServe will internally set <code>pipelineParallelSize = 2</code> and <code>tensorParallelSize = 8</code>.</p>
<p>Example configuration:</p>
<div class="highlight"><pre><span></span><code><span class="nt">workerSpec</span><span class="p">:</span><span class="w">    </span>
<span class="w">  </span><span class="nt">pipelineParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">  </span><span class="nt">tensorParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">worker-container</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;8&quot;</span>
</code></pre></div>
<hr />
<p><strong>Case 3: <code>pipelineParallelSize = 1</code>, <code>tensorParallelSize = 8</code>, <code>workerSpec.resources.requests.gpu = 8</code></strong></p>
<div class="highlight"><pre><span></span><code><span class="nt">workerSpec</span><span class="p">:</span><span class="w">    </span>
<span class="w">  </span><span class="nt">pipelineParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w">     </span><span class="c1"># default value is 1, so this field can be omitted</span>
<span class="w">  </span><span class="nt">tensorParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">worker-container</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">        </span><span class="nt">nvidia.com/gpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;8&quot;</span>
</code></pre></div>
<p>In this case, only the <strong>head node</strong> will be deployed,<br />
because the required total GPU count matches the GPU requested per Pod.</p>
<p>You can find more use-cases from <a href="https://github.com/kserve/kserve/pull/4356">here</a></p>
</div>
<h2 id="serve-the-hugging-face-vllm-model-using-2-nodes">Serve the Hugging Face vLLM Model Using 2 Nodes<a class="headerlink" href="#serve-the-hugging-face-vllm-model-using-2-nodes" title="Permanent link">&para;</a></h2>
<p>Follow these steps to serve the Hugging Face vLLM model using a multi-node setup.</p>
<h3 id="1-create-a-persistent-volume-claim-pvc">1. Create a Persistent Volume Claim (PVC)<a class="headerlink" href="#1-create-a-persistent-volume-claim-pvc" title="Permanent link">&para;</a></h3>
<p>First, create a PVC for model storage. Be sure to update <code>%fileStorageClassName%</code> with your actual storage class.</p>
<div class="highlight"><pre><span></span><code><span class="l l-Scalar l-Scalar-Plain">kubectl apply -f - &lt;&lt;EOF</span>
<span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">llama-3-8b-pvc</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">accessModes</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
<span class="w">  </span><span class="nt">volumeMode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Filesystem</span>
<span class="w">  </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">    </span><span class="nt">requests</span><span class="p">:</span>
<span class="w">      </span><span class="nt">storage</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50Gi</span>
<span class="w">  </span><span class="nt">storageClassName</span><span class="p">:</span><span class="w"> </span><span class="err">%</span><span class="l l-Scalar l-Scalar-Plain">fileStorageClassName%</span>
<span class="l l-Scalar l-Scalar-Plain">EOF</span>
</code></pre></div>
<h3 id="2-download-the-model-to-the-pvc">2. Download the Model to the PVC<a class="headerlink" href="#2-download-the-model-to-the-pvc" title="Permanent link">&para;</a></h3>
<p>To download the model, export your Hugging Face token (<code>HF_TEST_TOKEN</code>) as an environment variable. Replace <code>%token%</code> with your actual token.</p>
<div class="highlight"><pre><span></span><code><span class="l l-Scalar l-Scalar-Plain">export HF_TEST_TOKEN=%token%</span>
<span class="l l-Scalar l-Scalar-Plain">export MODEL=meta-llama/Meta-Llama-3-8B-Instruct</span>

<span class="l l-Scalar l-Scalar-Plain">curl -o download-model-to-pvc.yaml https://kserve.github.io/website/latest/modelserving/v1beta1/vLLM/huggingface/multi-node/download-model-to-pvc.yaml</span>
<span class="l l-Scalar l-Scalar-Plain">envsubst &lt; download-model-to-pvc.yaml | kubectl create -f -</span>
</code></pre></div>
<h3 id="3-create-a-servingruntime">3. Create a ServingRuntime<a class="headerlink" href="#3-create-a-servingruntime" title="Permanent link">&para;</a></h3>
<p>Apply the ServingRuntime configuration. Replace %TBD% with the path to your ServingRuntime YAML.</p>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>https://github.com/kserve/kserve/blob/master/config/runtimes/kserve-huggingfaceserver-multinode.yaml
</code></pre></div>
<h3 id="4-deploy-the-model">4. Deploy the model<a class="headerlink" href="#4-deploy-the-model" title="Permanent link">&para;</a></h3>
<p>Finally, deploy the model using the following InferenceService configuration:</p>
<div class="highlight"><pre><span></span><code><span class="l l-Scalar l-Scalar-Plain">kubectl apply -f - &lt;&lt;EOF</span>
<span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">annotations</span><span class="p">:</span>
<span class="w">    </span><span class="nt">serving.kserve.io/deploymentMode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">RawDeployment</span>
<span class="w">    </span><span class="nt">serving.kserve.io/autoscalerClass</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">none</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">huggingface-llama3</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">model</span><span class="p">:</span>
<span class="w">      </span><span class="nt">runtime</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-huggingfaceserver-multinode</span>
<span class="w">      </span><span class="nt">modelFormat</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">huggingface</span>
<span class="w">      </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pvc://llama-3-8b-pvc/hf/8b_instruction_tuned</span><span class="w">  </span>
<span class="w">    </span><span class="nt">workerSpec</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">pipelineParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">tensorParallelSize</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="l l-Scalar l-Scalar-Plain">EOF</span>
</code></pre></div>
<h2 id="check-inferenceservice-status">Check <code>InferenceService</code> status.<a class="headerlink" href="#check-inferenceservice-status" title="Permanent link">&para;</a></h2>
<p>To verify the status of your <code>InferenceService</code>, run the following command:</p>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>get<span class="w"> </span>inferenceservices<span class="w"> </span>huggingface-llama3
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>NAME<span class="w">                 </span>URL<span class="w">                                                   </span>READY<span class="w">   </span>PREV<span class="w">   </span>LATEST<span class="w">   </span>PREVROLLEDOUTREVISION<span class="w">   </span>LATESTREADYREVISION<span class="w">                          </span>AGE
huggingface-llama3<span class="w">   </span>http://huggingface-llama3.default.example.com<span class="w">                                          </span>5m
</code></pre></div>
</div>
<h2 id="check-gpu-resource-status">Check <code>GPU resource</code> status.<a class="headerlink" href="#check-gpu-resource-status" title="Permanent link">&para;</a></h2>
<p>To check the GPU resource status, follow these steps:</p>
<ol>
<li>
<p>Retrieve the pod names for the head and worker nodes:
    <div class="highlight"><pre><span></span><code><span class="c1"># Get pod name</span>
<span class="nv">podName</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>pod<span class="w"> </span>-l<span class="w"> </span><span class="nv">app</span><span class="o">=</span>isvc.huggingface-llama3-predictor<span class="w"> </span>--no-headers<span class="p">|</span>cut<span class="w"> </span>-d<span class="s1">&#39; &#39;</span><span class="w"> </span>-f1<span class="k">)</span>
<span class="nv">workerPodName</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>pod<span class="w"> </span>-l<span class="w"> </span><span class="nv">app</span><span class="o">=</span>isvc.huggingface-llama3-predictor-worker<span class="w"> </span>--no-headers<span class="p">|</span>cut<span class="w"> </span>-d<span class="s1">&#39; &#39;</span><span class="w"> </span>-f1<span class="k">)</span>
</code></pre></div></p>
</li>
<li>
<p>Check the GPU memory size for both the head and worker pods:
      <div class="highlight"><pre><span></span><code><span class="c1"># Check GPU memory size</span>
kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span><span class="nv">$podName</span><span class="w"> </span>--<span class="w"> </span>nvidia-smi
kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span><span class="nv">$workerPodName</span><span class="w"> </span>--<span class="w"> </span>nvidia-smi
</code></pre></div></p>
</li>
</ol>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>+-----------------------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">550</span>.90.07<span class="w">              </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">550</span>.90.07<span class="w">      </span>CUDA<span class="w"> </span>Version:<span class="w"> </span><span class="m">12</span>.4<span class="w">     </span><span class="p">|</span>
<span class="p">|</span>-----------------------------------------+------------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">                 </span>Persistence-M<span class="w"> </span><span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">          </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">   </span>Perf<span class="w">          </span>Pwr:Usage/Cap<span class="w"> </span><span class="p">|</span><span class="w">           </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                                         </span><span class="p">|</span><span class="w">                        </span><span class="p">|</span><span class="w">               </span>MIG<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">=========================================</span>+<span class="o">========================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>NVIDIA<span class="w"> </span>A10G<span class="w">                    </span>On<span class="w">  </span><span class="p">|</span><span class="w">   </span><span class="m">00000000</span>:00:1E.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                    </span><span class="m">0</span><span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span><span class="m">0</span>%<span class="w">   </span>33C<span class="w">    </span>P0<span class="w">             </span>71W<span class="w"> </span>/<span class="w">  </span>300W<span class="w"> </span><span class="p">|</span><span class="w">   </span>19031MiB<span class="w"> </span>/<span class="w">  </span>23028MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                                         </span><span class="p">|</span><span class="w">                        </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
+-----------------------------------------+------------------------+----------------------+
<span class="w">         </span>...<span class="w">                                                               </span>
+-----------------------------------------------------------------------------------------+
<span class="p">|</span><span class="w"> </span>NVIDIA-SMI<span class="w"> </span><span class="m">550</span>.90.07<span class="w">              </span>Driver<span class="w"> </span>Version:<span class="w"> </span><span class="m">550</span>.90.07<span class="w">      </span>CUDA<span class="w"> </span>Version:<span class="w"> </span><span class="m">12</span>.4<span class="w">     </span><span class="p">|</span>
<span class="p">|</span>-----------------------------------------+------------------------+----------------------+
<span class="p">|</span><span class="w"> </span>GPU<span class="w">  </span>Name<span class="w">                 </span>Persistence-M<span class="w"> </span><span class="p">|</span><span class="w"> </span>Bus-Id<span class="w">          </span>Disp.A<span class="w"> </span><span class="p">|</span><span class="w"> </span>Volatile<span class="w"> </span>Uncorr.<span class="w"> </span>ECC<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>Fan<span class="w">  </span>Temp<span class="w">   </span>Perf<span class="w">          </span>Pwr:Usage/Cap<span class="w"> </span><span class="p">|</span><span class="w">           </span>Memory-Usage<span class="w"> </span><span class="p">|</span><span class="w"> </span>GPU-Util<span class="w">  </span>Compute<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                                         </span><span class="p">|</span><span class="w">                        </span><span class="p">|</span><span class="w">               </span>MIG<span class="w"> </span>M.<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="o">=========================================</span>+<span class="o">========================</span>+<span class="o">======================</span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span>NVIDIA<span class="w"> </span>A10G<span class="w">                    </span>On<span class="w">  </span><span class="p">|</span><span class="w">   </span><span class="m">00000000</span>:00:1E.0<span class="w"> </span>Off<span class="w"> </span><span class="p">|</span><span class="w">                    </span><span class="m">0</span><span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">  </span><span class="m">0</span>%<span class="w">   </span>30C<span class="w">    </span>P0<span class="w">             </span>69W<span class="w"> </span>/<span class="w">  </span>300W<span class="w"> </span><span class="p">|</span><span class="w">   </span>18959MiB<span class="w"> </span>/<span class="w">  </span>23028MiB<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">0</span>%<span class="w">      </span>Default<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                                         </span><span class="p">|</span><span class="w">                        </span><span class="p">|</span><span class="w">                  </span>N/A<span class="w"> </span><span class="p">|</span>
+-----------------------------------------+------------------------+----------------------+<span class="w">             </span>
</code></pre></div>
</div>
<h2 id="perform-model-inference">Perform Model Inference<a class="headerlink" href="#perform-model-inference" title="Permanent link">&para;</a></h2>
<p>You can perform model inference by forwarding the port for testing purposes. Use the following command:</p>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>port-forward<span class="w"> </span>pod/<span class="nv">$podName</span><span class="w"> </span><span class="m">8080</span>:8080
</code></pre></div>
<p>The KServe Hugging Face vLLM runtime supports the following OpenAI endpoints for inference:</p>
<ul>
<li><code>/v1/completions</code></li>
<li><code>/v1/chat/completions</code> </li>
</ul>
<h4 id="sample-openai-completions-request">Sample OpenAI Completions request:<a class="headerlink" href="#sample-openai-completions-request" title="Permanent link">&para;</a></h4>
<p>To make a request to the OpenAI completions endpoint, use the following <code>curl</code> command:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>http://localhost:8080/openai/v1/completions<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;huggingface-llama3&quot;,</span>
<span class="s1">        &quot;prompt&quot;: &quot;At what temperature does Nitrogen boil?&quot;,</span>
<span class="s1">        &quot;max_tokens&quot;: 100,</span>
<span class="s1">        &quot;temperature&quot;: 0</span>
<span class="s1">    }&#39;</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cmpl-3bf2b04bac4a43548bc657c999e4fe5f&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;length&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;logprobs&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot; Nitrogen is a colorless, odorless, tasteless, and non-toxic gas. It is a member of the group 15 elements in the periodic table. Nitrogen is a very common element in the universe and is found in many compounds, including ammonia, nitric acid, and nitrate salts.\nThe boiling point of nitrogen is -195.8C (-320.4F) at standard atmospheric pressure. This means that at this temperature, nitrogen will change from a liquid to a&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1728348255</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;huggingface-llama3&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;system_fingerprint&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text_completion&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;completion_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">109</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span><span class="w">    </span>
</code></pre></div>
</div>
<h4 id="sample-openai-chat-request">Sample OpenAI Chat request:<a class="headerlink" href="#sample-openai-chat-request" title="Permanent link">&para;</a></h4>
<p>To make a request to the OpenAI chat completions endpoint, use the following <code>curl</code> command:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>http://localhost:8080/openai/v1/chat/completions<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;huggingface-llama3&quot;,</span>
<span class="s1">        &quot;messages&quot;:[{&quot;role&quot;:&quot;system&quot;,&quot;content&quot;:&quot;At what temperature does Nitrogen boil?&quot;}],</span>
<span class="s1">        &quot;max_tokens&quot;: 100,</span>
<span class="s1">        &quot;stream&quot;: false</span>
<span class="s1">       }&#39;</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cmpl-1201662139294b81b02aca115d7981b7&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;stop&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The boiling point of nitrogen is -195.8C (-320.44F) at a pressure of 1 atm.&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;tool_calls&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;function_call&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="nt">&quot;logprobs&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1728348754</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;huggingface-llama3&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;system_fingerprint&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat.completion&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;completion_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">26</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">19</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">45</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span><span class="w">    </span>
</code></pre></div>
</div>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../sdk_integration/" class="md-footer__link md-footer__link--prev" aria-label="Previous: OpenAI SDK Integration" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              OpenAI SDK Integration
            </div>
          </div>
        </a>
      
      
        
        <a href="../../../../storage/modelcache/localmodel/" class="md-footer__link md-footer__link--next" aria-label="Next: Model Cache" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Model Cache
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright  2021 The KServe Authors
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    <a href="https://github.com/kserve" target="_blank" rel="noopener" title="KServe Community on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    <a href="https://github.com/kserve/community/blob/main/README.md#questions-and-issues" target="_blank" rel="noopener" title="Join Slack" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.tabs", "navigation.tracking", "navigation.tabs.sticky", "navigation.top"], "search": "../../../../../assets/javascripts/workers/search.cefbb252.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.a5f8ea78.min.js"></script>
      
    
  </body>
</html>