---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  # this is the name of the runtime to add
  name: kserve-amdserver
spec:
  supportedModelFormats:
    # depending on the image you're using, and which platforms are added,
    # the supported formats could be different. For example, this assumes
    # that a ZenDNN image was created with only TF+ZenDNN
    - name: tensorflow
      version: "2"
  protocolVersions:
    # depending on the image you're using, it may not support both HTTP/REST
    # and gRPC, respectively. By default, both protocols are supported.
    - v2
    - grpc-v2
  containers:
    - name: kserve-container
      # provide the image name
      image: <image>
      # when the image starts, it will automatically launch the server
      # executable with the following arguments. While the ports used by
      # the server are configurable, there are some assumptions in KServe
      # with the default port values so it is recommended to not change them
      args:
        - proteus-server
        - --model-repository=/mnt/models
        - --enable-repository-watcher
        - --grpc-port=9000
        - --http-port=8080
      # the resources allowed to the service. If the image needs access to
      # hardware like FPGAs or GPUs, then those resources need to be added
      # here so Kubernetes can schedule pods on the appropriate nodes.
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
