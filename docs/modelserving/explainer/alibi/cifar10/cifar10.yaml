apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "cifar10"
spec:
  predictor:
    tensorflow:
      storageUri: "gs://seldon-models/tfserving/cifar10/resnet32"
      resources:
        requests:
          cpu: 0.1
          memory: 5Gi
        limits:
          memory: 10Gi
  explainer:
    containers:
      - name: kserve-container
        image: kserve/alibi-explainer:v0.12.1
        args:
          - --model_name=cifar10
          - --http_port=8080 
          - --predictor_host=cifar10-predictor.default 
          - --storage_uri=/mnt/models 
          - AnchorImages 
          - --batch_size=40 
          - --stop_on_first=True
        env:
          - name: STORAGE_URI
            value: "gs://kfserving-examples/models/tensorflow/cifar/explainer-0.9.1"
        resources:
          requests:
            cpu: 0.1
            memory: 5Gi
          limits:
            cpu: 1
            memory: 10Gi